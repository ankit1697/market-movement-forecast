{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: Create clean Python venv ===\n",
      "=== Step 2: Upgrade pip ===\n",
      "Requirement already satisfied: pip in ./.venv_mlops_sentiment/lib/python3.10/site-packages (25.3)\n",
      "=== Step 3: Install core dependencies ===\n",
      "Requirement already satisfied: numpy==1.26.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (1.26.4)\n",
      "Collecting pandas==2.2.2\n",
      "  Using cached pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy==1.11.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas==2.2.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas==2.2.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
      "Using cached pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pycaret 3.3.2 requires pandas<2.2.0, but you have pandas 2.2.2 which is incompatible.\n",
      "sktime 0.26.0 requires pandas<2.2.0,>=1.1, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed pandas-2.2.2\n",
      "Requirement already satisfied: scikit-learn==1.4.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from scikit-learn==1.4.2) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from scikit-learn==1.4.2) (3.6.0)\n",
      "Collecting matplotlib==3.8.4\n",
      "  Using cached matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: seaborn==0.13.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.21 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib==3.8.4) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from seaborn==0.13.2) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas>=1.2->seaborn==0.13.2) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib==3.8.4) (1.17.0)\n",
      "Using cached matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Installing collected packages: matplotlib\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.5\n",
      "    Uninstalling matplotlib-3.7.5:\n",
      "      Successfully uninstalled matplotlib-3.7.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pycaret 3.3.2 requires matplotlib<3.8.0, but you have matplotlib 3.8.4 which is incompatible.\n",
      "pycaret 3.3.2 requires pandas<2.2.0, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed matplotlib-3.8.4\n",
      "Requirement already satisfied: yfinance==0.2.44 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (0.2.44)\n",
      "Requirement already satisfied: pandas>=1.3.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (2.32.5)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (0.0.12)\n",
      "Requirement already satisfied: lxml>=4.9.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (6.0.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (4.5.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (2025.2)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (2.4.7)\n",
      "Requirement already satisfied: peewee>=3.16.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (3.18.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (4.14.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from yfinance==0.2.44) (1.1)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.44) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from beautifulsoup4>=4.11.1->yfinance==0.2.44) (4.15.0)\n",
      "Requirement already satisfied: six>=1.9 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from html5lib>=1.1->yfinance==0.2.44) (1.17.0)\n",
      "Requirement already satisfied: webencodings in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from html5lib>=1.1->yfinance==0.2.44) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance==0.2.44) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas>=1.3.0->yfinance==0.2.44) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.44) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.44) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.44) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.31->yfinance==0.2.44) (2025.11.12)\n",
      "Requirement already satisfied: nltk==3.9.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nltk==3.9.1) (8.3.1)\n",
      "Requirement already satisfied: joblib in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nltk==3.9.1) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nltk==3.9.1) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nltk==3.9.1) (4.67.1)\n",
      "=== Step 4: Install PyCaret (+ all models) ===\n",
      "Requirement already satisfied: pycaret==3.3.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (3.3.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (8.37.0)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (8.1.8)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.67.1)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.26.4)\n",
      "Collecting pandas<2.2.0 (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2)\n",
      "  Using cached pandas-2.1.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jinja2>=3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.1.6)\n",
      "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.11.4)\n",
      "Requirement already satisfied: joblib<1.4,>=1.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>1.4.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.4.2)\n",
      "Requirement already satisfied: pyod>=1.1.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.0.6)\n",
      "Requirement already satisfied: imbalanced-learn>=0.12.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.14.0)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.7.0)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.6.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.62.1)\n",
      "Requirement already satisfied: requests>=2.27.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.32.5)\n",
      "Requirement already satisfied: psutil>=5.9.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (7.1.3)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (8.7.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (5.10.4)\n",
      "Requirement already satisfied: cloudpickle in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.1.2)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.1.0)\n",
      "Requirement already satisfied: xxhash in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.6.0)\n",
      "Collecting matplotlib<3.8.0 (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2)\n",
      "  Using cached matplotlib-3.7.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.3.7)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.5)\n",
      "Requirement already satisfied: plotly>=5.14.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (5.24.1)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.2.0)\n",
      "Requirement already satisfied: schemdraw==0.15 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.15)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.11.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.14.5)\n",
      "Requirement already satisfied: sktime==0.26.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.26.0)\n",
      "Requirement already satisfied: tbats>=1.1.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.1.3)\n",
      "Requirement already satisfied: pmdarima>=2.0.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.0.4)\n",
      "Requirement already satisfied: wurlitzer in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.1.1)\n",
      "Requirement already satisfied: kmodes>=0.11.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.12.2)\n",
      "Requirement already satisfied: mlxtend>=0.19.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.23.4)\n",
      "Requirement already satisfied: statsforecast<1.6.0,>=0.5.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (1.5.0)\n",
      "Requirement already satisfied: catboost<1.2,>=0.23.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (1.1.1)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (3.1.2)\n",
      "Requirement already satisfied: shap~=0.44.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.44.1)\n",
      "Requirement already satisfied: interpret>=0.2.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.7.3)\n",
      "Requirement already satisfied: umap-learn>=0.5.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.5.7)\n",
      "Requirement already satisfied: pyyaml in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (6.0.3)\n",
      "Requirement already satisfied: ydata-profiling>=4.3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (4.18.0)\n",
      "Requirement already satisfied: explainerdashboard>=0.3.8 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.5.1)\n",
      "Requirement already satisfied: fairlearn==0.7.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pycaret[analysis,models]==3.3.2) (0.7.0)\n",
      "Requirement already satisfied: packaging in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from sktime==0.26.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (25.0)\n",
      "Requirement already satisfied: scikit-base<0.8.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from sktime==0.26.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.7.8)\n",
      "Requirement already satisfied: graphviz in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from catboost<1.2,>=0.23.2->pycaret[analysis,models]==3.3.2) (0.21)\n",
      "Requirement already satisfied: six in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from catboost<1.2,>=0.23.2->pycaret[analysis,models]==3.3.2) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.4.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from matplotlib<3.8.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas<2.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pandas<2.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2025.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from scikit-learn>1.4.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.6.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from shap~=0.44.0->pycaret[analysis,models]==3.3.2) (0.0.7)\n",
      "Requirement already satisfied: fugue>=0.8.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from statsforecast<1.6.0,>=0.5.5->pycaret[analysis,models]==3.3.2) (0.9.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from category-encoders>=2.4.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.0.2)\n",
      "Requirement already satisfied: click in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (8.3.1)\n",
      "Requirement already satisfied: dash-auth in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.3.0)\n",
      "Requirement already satisfied: dash-bootstrap-components<3,>=1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.7.1)\n",
      "Requirement already satisfied: dash<3,>=2.10 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.18.2)\n",
      "Requirement already satisfied: dtreeviz>=2.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.2.2)\n",
      "Requirement already satisfied: flask-simplelogin in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (0.2.0)\n",
      "Requirement already satisfied: flask-wtf>=1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.2.2)\n",
      "Requirement already satisfied: jupyter-dash>=0.4.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (0.4.2)\n",
      "Requirement already satisfied: oyaml in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.0)\n",
      "Requirement already satisfied: waitress in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (3.0.2)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (3.0.3)\n",
      "Requirement already satisfied: Werkzeug<3.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (3.0.6)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (5.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (4.15.0)\n",
      "Requirement already satisfied: retrying in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.4.2)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.6.0)\n",
      "Requirement already satisfied: setuptools in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (79.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from Flask<3.1,>=1.0.4->dash<3,>=2.10->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from plotly>=5.14.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (9.1.2)\n",
      "Requirement already satisfied: colour in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (0.1.5)\n",
      "Requirement already satisfied: pytest in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (9.0.1)\n",
      "Requirement already satisfied: wtforms in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from flask-wtf>=1.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (3.2.1)\n",
      "Requirement already satisfied: triad>=1.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from fugue>=0.8.1->statsforecast<1.6.0,>=0.5.5->pycaret[analysis,models]==3.3.2) (1.0.0)\n",
      "Requirement already satisfied: adagio>=0.2.6 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from fugue>=0.8.1->statsforecast<1.6.0,>=0.5.5->pycaret[analysis,models]==3.3.2) (0.2.6)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from importlib-metadata>=4.12.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.23.0)\n",
      "Requirement already satisfied: interpret-core==0.7.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.7.3)\n",
      "Requirement already satisfied: aplr>=10.6.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (10.19.1)\n",
      "Requirement already satisfied: ipykernel>=4.10.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (7.1.0)\n",
      "Requirement already satisfied: dill>=0.2.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.4.0)\n",
      "Requirement already satisfied: SALib>=1.3.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (1.5.1)\n",
      "Requirement already satisfied: dash-cytoscape>=0.1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (1.0.2)\n",
      "Requirement already satisfied: gevent>=1.3.6 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (25.9.1)\n",
      "Requirement already satisfied: greenlet>=3.2.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (3.2.4)\n",
      "Requirement already satisfied: zope.event in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (6.1)\n",
      "Requirement already satisfied: zope.interface in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (8.1.1)\n",
      "Requirement already satisfied: appnope>=0.1.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.2.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (1.8.17)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.2.1)\n",
      "Requirement already satisfied: pyzmq>=25 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (27.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (6.5.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (5.14.3)\n",
      "Requirement already satisfied: decorator in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.19.2)\n",
      "Requirement already satisfied: stack_data in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.2.14)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ipywidgets>=7.6.5->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.0.16)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.8.5)\n",
      "Requirement already satisfied: platformdirs>=2.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (4.5.0)\n",
      "Requirement already satisfied: ansi2html in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jupyter-dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.9.2)\n",
      "Requirement already satisfied: choreographer>=1.1.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (1.2.1)\n",
      "Requirement already satisfied: logistro>=1.0.8 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.0.1)\n",
      "Requirement already satisfied: orjson>=3.10.15 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.11.4)\n",
      "Requirement already satisfied: pytest-timeout>=2.4.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from kaleido>=0.2.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.4.0)\n",
      "Requirement already satisfied: simplejson>=3.19.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from choreographer>=1.1.1->kaleido>=0.2.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.20.2)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (4.25.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.30.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from numba>=0.55.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.45.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.7.0)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from plotly-resampler>=0.8.3.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.1.4.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.2.2)\n",
      "Requirement already satisfied: urllib3 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pmdarima>=2.0.4->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.5.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pytest->dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pytest->dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (1.6.0)\n",
      "Requirement already satisfied: tomli>=1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pytest->dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[analysis,models]==3.3.2) (2.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.27.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.27.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from requests>=2.27.1->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2025.11.12)\n",
      "Requirement already satisfied: multiprocess in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.7.3->interpret>=0.2.7->pycaret[analysis,models]==3.3.2) (0.70.18)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from triad>=1.0.0->fugue>=0.8.1->statsforecast<1.6.0,>=0.5.5->pycaret[analysis,models]==3.3.2) (22.0.0)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from triad>=1.0.0->fugue>=0.8.1->statsforecast<1.6.0,>=0.5.5->pycaret[analysis,models]==3.3.2) (2025.12.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from umap-learn>=0.5.2->pycaret[analysis,models]==3.3.2) (0.5.13)\n",
      "Requirement already satisfied: pydantic<3,>=2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (2.12.5)\n",
      "Requirement already satisfied: visions<0.8.2,>=0.7.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.8.1)\n",
      "Requirement already satisfied: minify-html>=0.15.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.18.1)\n",
      "Requirement already satisfied: filetype>=1.0.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.2.0)\n",
      "Requirement already satisfied: phik<0.13,>=0.12.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.12.5)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.13.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.12)\n",
      "Requirement already satisfied: typeguard<5,>=4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (4.4.4)\n",
      "Requirement already satisfied: imagehash==4.3.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (4.3.2)\n",
      "Requirement already satisfied: wordcloud>=1.9.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.9.4)\n",
      "Requirement already satisfied: dacite<2,>=1.9 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.9.2)\n",
      "Requirement already satisfied: PyWavelets in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from imagehash==4.3.2->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pydantic<3,>=2->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pydantic<3,>=2->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from pydantic<3,>=2->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (0.4.2)\n",
      "Requirement already satisfied: networkx>=2.4 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (3.4.2)\n",
      "Requirement already satisfied: puremagic in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[analysis,models]==3.3.2) (1.30)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from stack_data->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from stack_data->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv_mlops_sentiment/lib/python3.10/site-packages (from stack_data->ipython>=5.5.0->pycaret==3.3.2->pycaret[analysis,models]==3.3.2) (0.2.3)\n",
      "Using cached matplotlib-3.7.5-cp310-cp310-macosx_11_0_arm64.whl (7.3 MB)\n",
      "Using cached pandas-2.1.4-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "Installing collected packages: pandas, matplotlib\n",
      "\u001b[2K  Attempting uninstall: pandas\n",
      "\u001b[2K    Found existing installation: pandas 2.2.2\n",
      "\u001b[2K    Uninstalling pandas-2.2.2:\n",
      "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
      "\u001b[2K  Attempting uninstall: matplotlib━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: matplotlib 3.8.4m \u001b[32m0/2\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling matplotlib-3.8.4:━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled matplotlib-3.8.4━━m \u001b[32m0/2\u001b[0m [pandas]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/2\u001b[0m [matplotlib]━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed matplotlib-3.7.5 pandas-2.1.4\n",
      "=== Step 5: Download NLTK VADER ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ultraronachart/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 6: If macOS, install libomp for LightGBM ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "✔︎ JSON API cask.jws.json\n",
      "✔︎ JSON API formula.jws.json\n",
      "Warning: libomp 21.1.7 is already installed and up-to-date.\n",
      "To reinstall 21.1.7, run:\n",
      "  brew reinstall libomp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libomp installed and flags exported.\n",
      "=== All dependencies installed successfully ===\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "set -e\n",
    "\n",
    "echo \"=== Step 1: Create clean Python venv ===\"\n",
    "python3.10 -m venv .venv_mlops_sentiment\n",
    "source .venv_mlops_sentiment/bin/activate\n",
    "\n",
    "echo \"=== Step 2: Upgrade pip ===\"\n",
    "pip install --upgrade pip\n",
    "\n",
    "echo \"=== Step 3: Install core dependencies ===\"\n",
    "pip install numpy==1.26.4 pandas==2.2.2 scipy==1.11.4\n",
    "pip install scikit-learn==1.4.2\n",
    "pip install matplotlib==3.8.4 seaborn==0.13.2\n",
    "pip install yfinance==0.2.44\n",
    "pip install nltk==3.9.1\n",
    "\n",
    "echo \"=== Step 4: Install PyCaret (+ all models) ===\"\n",
    "pip install 'pycaret[analysis,models]==3.3.2'\n",
    "\n",
    "echo \"=== Step 5: Download NLTK VADER ===\"\n",
    "python - <<'EOF'\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "EOF\n",
    "\n",
    "echo \"=== Step 6: If macOS, install libomp for LightGBM ===\"\n",
    "if [[ \"$OSTYPE\" == \"darwin\"* ]]; then\n",
    "    brew install libomp || true\n",
    "    export LDFLAGS=\"-L/opt/homebrew/opt/libomp/lib\"\n",
    "    export CPPFLAGS=\"-I/opt/homebrew/opt/libomp/include\"\n",
    "    echo \"libomp installed and flags exported.\"\n",
    "fi\n",
    "\n",
    "echo \"=== All dependencies installed successfully ===\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download news data to make a sentiment score and combine to both alternative sentiment score and S&P500 to make a \"main database\" prepare for run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import news text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "### Import News .csv file ###\n",
    "# Import CNBC news\n",
    "path_cnbc = \"/Users/ultraronachart/Documents/Macine Learning Operations/Final_project/data/raw/cnbc_headlines.csv\"\n",
    "cnbc = pd.read_csv(path_cnbc)\n",
    "\n",
    "# Import Guardian news\n",
    "path_gd = \"/Users/ultraronachart/Documents/Macine Learning Operations/Final_project/data/raw/guardian_headlines.csv\"\n",
    "guardian = pd.read_csv(path_gd)\n",
    "\n",
    "# Import Reuters news\n",
    "path_reuters = \"/Users/ultraronachart/Documents/Macine Learning Operations/Final_project/data/raw/reuters_headlines.csv\"\n",
    "reuters = pd.read_csv(path_reuters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare each source dataframe to merge later ###\n",
    "def prepare_source(df, source_name, has_description=True):\n",
    "    \"\"\"\n",
    "    Standardize column names to be lower case, add the source column, and replace description = headline if there is no description. \n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Rename columns\n",
    "    rename_map = {\n",
    "        \"Headlines\": \"headline\",\n",
    "        \"Time\": \"time\",\n",
    "        \"Description\": \"description\"\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # Replace description = headline if there is no description\n",
    "    if not has_description:\n",
    "        df['description'] = df['headline']\n",
    "\n",
    "    df['source'] = source_name\n",
    "\n",
    "    # Sort order of the columns\n",
    "    return df[[\"time\", \"headline\", \"description\", \"source\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_std = prepare_source(cnbc, \"cnbc\", has_description=True)\n",
    "guardian_std = prepare_source(guardian, \"guardian\", has_description=False)\n",
    "reuters_std = prepare_source(reuters, \"reuters\", has_description=True)\n",
    "\n",
    "# Append (stack) all rows on top of each other\n",
    "news_all = pd.concat([cnbc_std, guardian_std, reuters_std], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53272 entries, 0 to 53649\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   time         53272 non-null  datetime64[ns]\n",
      " 1   headline     53272 non-null  object        \n",
      " 2   description  53272 non-null  object        \n",
      " 3   source       53272 non-null  object        \n",
      " 4   date         53272 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(4)\n",
      "memory usage: 2.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-17 19:51:00</td>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer recommended buying...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-17 19:33:00</td>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer rings the lightnin...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-17 19:25:00</td>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>\"We'll pay more for the earnings of the non-Co...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-17 16:24:00</td>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>Keith Bliss, IQ Capital CEO, joins \"Closing Be...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>2020-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-07-16 19:36:00</td>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>\"Look for the stocks of high-quality companies...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>2020-07-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time                                           headline  \\\n",
       "0 2020-07-17 19:51:00  Jim Cramer: A better way to invest in the Covi...   \n",
       "1 2020-07-17 19:33:00     Cramer's lightning round: I would own Teradyne   \n",
       "3 2020-07-17 19:25:00  Cramer's week ahead: Big week for earnings, ev...   \n",
       "4 2020-07-17 16:24:00  IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "5 2020-07-16 19:36:00  Wall Street delivered the 'kind of pullback I'...   \n",
       "\n",
       "                                         description source        date  \n",
       "0  \"Mad Money\" host Jim Cramer recommended buying...   cnbc  2020-07-17  \n",
       "1  \"Mad Money\" host Jim Cramer rings the lightnin...   cnbc  2020-07-17  \n",
       "3  \"We'll pay more for the earnings of the non-Co...   cnbc  2020-07-17  \n",
       "4  Keith Bliss, IQ Capital CEO, joins \"Closing Be...   cnbc  2020-07-17  \n",
       "5  \"Look for the stocks of high-quality companies...   cnbc  2020-07-16  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Basic text cleaning ###\n",
    "\n",
    "# Ensure headline/description are strings and strip whitespace\n",
    "news_all[\"headline\"] = news_all[\"headline\"].astype(str).str.strip()\n",
    "news_all[\"description\"] = news_all[\"description\"].astype(str).str.strip()\n",
    "\n",
    "# Sometimes there are weird line breaks / multiple spaces in Guardian\n",
    "news_all[\"headline\"] = news_all[\"headline\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "news_all[\"description\"] = news_all[\"description\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "# Drop rows where headline is empty after stripping\n",
    "news_all = news_all[news_all[\"headline\"].str.len() > 0]\n",
    "\n",
    "# --- Time parsing & cleaning ---\n",
    "\n",
    "# Convert time column to datetime, coerce invalid formats to NaT (missing)\n",
    "news_all[\"time\"] = pd.to_datetime(news_all[\"time\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows where time could not be parsed\n",
    "news_all = news_all.dropna(subset=[\"time\"])\n",
    "\n",
    "# Create a pure date column (will be super useful later when we aggregate per day)\n",
    "news_all[\"date\"] = news_all[\"time\"].dt.date\n",
    "\n",
    "# --- Handle duplicates ---\n",
    "\n",
    "# Drop exact duplicate rows (same time, headline, description, source)\n",
    "news_all = news_all.drop_duplicates(subset=[\"time\", \"headline\", \"description\", \"source\"])\n",
    "\n",
    "news_all.info()\n",
    "news_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the sentiment score using NLTK (1st sentiment analysis approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/mlops_sentiment/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/mlops_sentiment/lib/python3.10/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/mlops_sentiment/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/mlops_sentiment/lib/python3.10/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/mlops_sentiment/lib/python3.10/site-packages (from nltk) (4.67.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/ultraronachart/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create the sentiment of each article ###\n",
    "!pip install nltk\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_all[\"text\"] = (\n",
    "    news_all[\"headline\"].fillna(\"\") \n",
    "    + \". \" + \n",
    "    news_all[\"description\"].fillna(\"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(text):\n",
    "    return sia.polarity_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>compound</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-17 19:51:00</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-17 19:33:00</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>-0.2023</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-17 19:25:00</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-17 16:24:00</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-07-16 19:36:00</td>\n",
       "      <td>2020-07-16</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 time        date source  \\\n",
       "0 2020-07-17 19:51:00  2020-07-17   cnbc   \n",
       "1 2020-07-17 19:33:00  2020-07-17   cnbc   \n",
       "3 2020-07-17 19:25:00  2020-07-17   cnbc   \n",
       "4 2020-07-17 16:24:00  2020-07-17   cnbc   \n",
       "5 2020-07-16 19:36:00  2020-07-16   cnbc   \n",
       "\n",
       "                                            headline  compound    pos    neg  \\\n",
       "0  Jim Cramer: A better way to invest in the Covi...    0.5267  0.232  0.098   \n",
       "1     Cramer's lightning round: I would own Teradyne   -0.2023  0.074  0.098   \n",
       "3  Cramer's week ahead: Big week for earnings, ev...    0.3612  0.078  0.038   \n",
       "4  IQ Capital CEO Keith Bliss says tech and healt...    0.8126  0.183  0.000   \n",
       "5  Wall Street delivered the 'kind of pullback I'...   -0.6597  0.000  0.134   \n",
       "\n",
       "     neu  \n",
       "0  0.671  \n",
       "1  0.828  \n",
       "3  0.885  \n",
       "4  0.817  \n",
       "5  0.866  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = news_all['text'].apply(get_sentiment_score).apply(pd.Series)\n",
    "\n",
    "news_all = pd.concat([news_all, sentiment_df], axis=1)\n",
    "\n",
    "news_all[[\"time\", \"date\", \"source\", \"headline\", \"compound\", \"pos\", \"neg\", \"neu\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931 entries, 0 to 930\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   date                     931 non-null    object \n",
      " 1   sentiment_compound_mean  931 non-null    float64\n",
      " 2   sentiment_compound_std   931 non-null    float64\n",
      " 3   sentiment_compound_min   931 non-null    float64\n",
      " 4   sentiment_compound_max   931 non-null    float64\n",
      " 5   sentiment_pos_mean       931 non-null    float64\n",
      " 6   sentiment_neg_mean       931 non-null    float64\n",
      " 7   sentiment_neu_mean       931 non-null    float64\n",
      " 8   num_news                 931 non-null    int64  \n",
      "dtypes: float64(7), int64(1), object(1)\n",
      "memory usage: 65.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "daily_sentiment = (\n",
    "    news_all\n",
    "    .groupby(\"date\")\n",
    "    .agg(\n",
    "        sentiment_compound_mean=(\"compound\", \"mean\"),\n",
    "        sentiment_compound_std=(\"compound\", \"std\"),\n",
    "        sentiment_compound_min=(\"compound\", \"min\"),\n",
    "        sentiment_compound_max=(\"compound\", \"max\"),\n",
    "        sentiment_pos_mean=(\"pos\", \"mean\"),\n",
    "        sentiment_neg_mean=(\"neg\", \"mean\"),\n",
    "        sentiment_neu_mean=(\"neu\", \"mean\"),\n",
    "        num_news=(\"headline\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Some days may have only 1 article → std will be NaN\n",
    "daily_sentiment[\"sentiment_compound_std\"] = daily_sentiment[\"sentiment_compound_std\"].fillna(0.0)\n",
    "\n",
    "print(daily_sentiment.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the S&P 500 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1478.000000</td>\n",
       "      <td>1438.359985</td>\n",
       "      <td>1469.250000</td>\n",
       "      <td>931800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1009000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1085500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1092300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1225200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        close         high          low         open      volume\n",
       "0  2000-01-03  1455.219971  1478.000000  1438.359985  1469.250000   931800000\n",
       "1  2000-01-04  1399.420044  1455.219971  1397.430054  1455.219971  1009000000\n",
       "2  2000-01-05  1402.109985  1413.270020  1377.680054  1399.420044  1085500000\n",
       "3  2000-01-06  1403.449951  1411.900024  1392.099976  1402.109985  1092300000\n",
       "4  2000-01-07  1441.469971  1441.469971  1400.729980  1403.449951  1225200000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500 = yf.download(\"^GSPC\", start=\"2000-01-01\", progress=False)\n",
    "\n",
    "# Flatten column names if they are MultiIndex:\n",
    "if isinstance(sp500.columns, pd.MultiIndex):\n",
    "    sp500.columns = [col[0] for col in sp500.columns]  # take the high level\n",
    "\n",
    "    # Move Date index to a column\n",
    "sp500 = sp500.reset_index()\n",
    "\n",
    "# Rename Date to date, and others to lowercase\n",
    "sp500 = sp500.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Close\": \"close\",\n",
    "    \"Open\": \"open\",\n",
    "    \"High\": \"high\",\n",
    "    \"Low\": \"low\",\n",
    "    \"Volume\": \"volume\",\n",
    "    \"Price\": \"price\"\n",
    "})\n",
    "\n",
    "# Convert to date only (no time)\n",
    "sp500[\"date\"] = pd.to_datetime(sp500[\"date\"]).dt.date\n",
    "\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>return_t</th>\n",
       "      <th>return_t_plus_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1397.430054</td>\n",
       "      <td>1455.219971</td>\n",
       "      <td>1009000000</td>\n",
       "      <td>-3.834467</td>\n",
       "      <td>0.192218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1413.270020</td>\n",
       "      <td>1377.680054</td>\n",
       "      <td>1399.420044</td>\n",
       "      <td>1085500000</td>\n",
       "      <td>0.192218</td>\n",
       "      <td>0.095568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1411.900024</td>\n",
       "      <td>1392.099976</td>\n",
       "      <td>1402.109985</td>\n",
       "      <td>1092300000</td>\n",
       "      <td>0.095568</td>\n",
       "      <td>2.709040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1400.729980</td>\n",
       "      <td>1403.449951</td>\n",
       "      <td>1225200000</td>\n",
       "      <td>2.709040</td>\n",
       "      <td>1.118997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-01-10</td>\n",
       "      <td>1457.599976</td>\n",
       "      <td>1464.359985</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1441.469971</td>\n",
       "      <td>1064800000</td>\n",
       "      <td>1.118997</td>\n",
       "      <td>-1.306251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        close         high          low         open      volume  \\\n",
       "1  2000-01-04  1399.420044  1455.219971  1397.430054  1455.219971  1009000000   \n",
       "2  2000-01-05  1402.109985  1413.270020  1377.680054  1399.420044  1085500000   \n",
       "3  2000-01-06  1403.449951  1411.900024  1392.099976  1402.109985  1092300000   \n",
       "4  2000-01-07  1441.469971  1441.469971  1400.729980  1403.449951  1225200000   \n",
       "5  2000-01-10  1457.599976  1464.359985  1441.469971  1441.469971  1064800000   \n",
       "\n",
       "   return_t  return_t_plus_1  \n",
       "1 -3.834467         0.192218  \n",
       "2  0.192218         0.095568  \n",
       "3  0.095568         2.709040  \n",
       "4  2.709040         1.118997  \n",
       "5  1.118997        -1.306251  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daily return (%)\n",
    "sp500[\"return_t\"] = sp500[\"close\"].pct_change() * 100\n",
    "\n",
    "# Next-day return (%), our target\n",
    "sp500[\"return_t_plus_1\"] = sp500[\"return_t\"].shift(-1)\n",
    "\n",
    "# Drop the first and last rows where returns are NaN\n",
    "sp500 = sp500.dropna(subset=[\"return_t\", \"return_t_plus_1\"])\n",
    "\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge VADER sentiment with S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_compound_mean</th>\n",
       "      <th>sentiment_compound_std</th>\n",
       "      <th>sentiment_compound_min</th>\n",
       "      <th>sentiment_compound_max</th>\n",
       "      <th>sentiment_pos_mean</th>\n",
       "      <th>sentiment_neg_mean</th>\n",
       "      <th>sentiment_neu_mean</th>\n",
       "      <th>num_news</th>\n",
       "      <th>return_t</th>\n",
       "      <th>return_t_plus_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>-0.110590</td>\n",
       "      <td>0.476690</td>\n",
       "      <td>-0.8807</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>40</td>\n",
       "      <td>0.536281</td>\n",
       "      <td>-0.323027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-0.261770</td>\n",
       "      <td>0.481266</td>\n",
       "      <td>-0.8750</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>0.120250</td>\n",
       "      <td>0.852800</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.323027</td>\n",
       "      <td>-0.082789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>-0.9698</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.068950</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>0.198566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>0.077030</td>\n",
       "      <td>0.462032</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.086550</td>\n",
       "      <td>0.799550</td>\n",
       "      <td>20</td>\n",
       "      <td>0.198566</td>\n",
       "      <td>-0.045817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>0.037161</td>\n",
       "      <td>0.530048</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.078609</td>\n",
       "      <td>0.811913</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.045817</td>\n",
       "      <td>-0.105842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sentiment_compound_mean  sentiment_compound_std  \\\n",
       "0  2017-12-18                -0.110590                0.476690   \n",
       "1  2017-12-19                -0.261770                0.481266   \n",
       "2  2017-12-20                 0.031795                0.498608   \n",
       "3  2017-12-21                 0.077030                0.462032   \n",
       "4  2017-12-22                 0.037161                0.530048   \n",
       "\n",
       "   sentiment_compound_min  sentiment_compound_max  sentiment_pos_mean  \\\n",
       "0                 -0.8807                  0.8402            0.061600   \n",
       "1                 -0.8750                  0.6759            0.026950   \n",
       "2                 -0.9698                  0.8750            0.068950   \n",
       "3                 -0.6808                  0.7650            0.113900   \n",
       "4                 -0.8481                  0.8750            0.109478   \n",
       "\n",
       "   sentiment_neg_mean  sentiment_neu_mean  num_news  return_t  return_t_plus_1  \n",
       "0            0.104625            0.833800        40  0.536281        -0.323027  \n",
       "1            0.120250            0.852800        20 -0.323027        -0.082789  \n",
       "2            0.078900            0.852150        20 -0.082789         0.198566  \n",
       "3            0.086550            0.799550        20  0.198566        -0.045817  \n",
       "4            0.078609            0.811913        23 -0.045817        -0.105842  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.merge(\n",
    "    daily_sentiment,\n",
    "    sp500[[\"date\", \"return_t\", \"return_t_plus_1\"]],\n",
    "    on=\"date\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Sort by date just to be safe\n",
    "model_df_sorted = model_df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "model_df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_bucket\n",
      "up               189\n",
      "slightly_up      172\n",
      "down             148\n",
      "slightly_down    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Shares:\n",
      " return_bucket\n",
      "up               0.292117\n",
      "slightly_up      0.265842\n",
      "down             0.228748\n",
      "slightly_down    0.213292\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def label_return_bucket(r):\n",
    "    if r > 0.5:\n",
    "        return \"up\"\n",
    "    elif r > 0:\n",
    "        return \"slightly_up\"\n",
    "    elif r >= -0.5:\n",
    "        return \"slightly_down\"\n",
    "    else:\n",
    "        return \"down\"\n",
    "\n",
    "model_df_sorted = model_df_sorted.copy()\n",
    "model_df_sorted[\"return_bucket\"] = model_df_sorted[\"return_t_plus_1\"].apply(label_return_bucket)\n",
    "\n",
    "# Quick check: counts of each bucket\n",
    "print(model_df_sorted[\"return_bucket\"].value_counts())\n",
    "print(\"\\nShares:\\n\", model_df_sorted[\"return_bucket\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts (all data):\n",
      "direction_binary\n",
      "up      361\n",
      "down    286\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class shares:\n",
      "direction_binary\n",
      "up      0.55796\n",
      "down    0.44204\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def label_up_down(r):\n",
    "    return \"up\" if r > 0 else \"down\"\n",
    "\n",
    "model_df_sorted = model_df_sorted.copy()\n",
    "model_df_sorted['direction_binary'] = model_df_sorted['return_t_plus_1'].apply(label_up_down)\n",
    "\n",
    "print(\"Class counts (all data):\")\n",
    "print(model_df_sorted[\"direction_binary\"].value_counts())\n",
    "print(\"\\nClass shares:\")\n",
    "print(model_df_sorted[\"direction_binary\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download GenAI sentiment data and merge with the Main database (model_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import daily sentiment\n",
    "path_sentiment = \"/Users/ultraronachart/Documents/Macine Learning Operations/Final_project/data/raw/daily_sentiment.csv\"\n",
    "daily_sentiment = pd.read_csv(path_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment[\"sentiment_score\"] = (daily_sentiment[\"Positive\"] - daily_sentiment[\"Negative\"]) / (\n",
    "    daily_sentiment[\"Positive\"] + daily_sentiment[\"Negative\"] + daily_sentiment[\"Neutral\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment[\"net_sentiment\"] = (daily_sentiment[\"Positive\"] - daily_sentiment[\"Negative\"]) / (\n",
    "    daily_sentiment[\"Positive\"] + daily_sentiment[\"Negative\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment[\"date\"] = pd.to_datetime(daily_sentiment[\"date\"])\n",
    "model_df_sorted[\"date\"] = pd.to_datetime(model_df_sorted[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_merged = model_df_sorted.merge(\n",
    "    daily_sentiment[[\"date\", \"sentiment_score\", \"net_sentiment\"]],\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the sentiment by category data (Hritik file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import News .csv file \n",
    "path_data = \"/Users/ultraronachart/Documents/Macine Learning Operations/Final_project/data/processed/csv/all_news_final.csv\"\n",
    "all_news = pd.read_csv(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>category</th>\n",
       "      <th>category_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7/17/20</td>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer recommended buying...</td>\n",
       "      <td>Jim Cramer: A better way to invest in the Covi...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>0.44</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7/17/20</td>\n",
       "      <td>Cramer's lightning round: I would own Teradyne</td>\n",
       "      <td>\"Mad Money\" host Jim Cramer rings the lightnin...</td>\n",
       "      <td>Cramer's lightning round: I would own Teradyne...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7/17/20</td>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>\"We'll pay more for the earnings of the non-Co...</td>\n",
       "      <td>Cramer's week ahead: Big week for earnings, ev...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7/17/20</td>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>Keith Bliss, IQ Capital CEO, joins \"Closing Be...</td>\n",
       "      <td>IQ Capital CEO Keith Bliss says tech and healt...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7/16/20</td>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>\"Look for the stocks of high-quality companies...</td>\n",
       "      <td>Wall Street delivered the 'kind of pullback I'...</td>\n",
       "      <td>cnbc</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53267</th>\n",
       "      <td>53267</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>Malaysia says never hired British data firm at...</td>\n",
       "      <td>The Malaysian government and the ruling party ...</td>\n",
       "      <td>Malaysia says never hired British data firm at...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Technology</td>\n",
       "      <td>0.60</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53268</th>\n",
       "      <td>53268</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>Prosecutors search Volkswagen headquarters in ...</td>\n",
       "      <td>German prosecutors said on Tuesday they had se...</td>\n",
       "      <td>Prosecutors search Volkswagen headquarters in ...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Automobile</td>\n",
       "      <td>0.97</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53269</th>\n",
       "      <td>53269</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>McDonald's sets greenhouse gas reduction targets</td>\n",
       "      <td>McDonald's Corp on Tuesday announced an approv...</td>\n",
       "      <td>McDonald's sets greenhouse gas reduction targe...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Energy</td>\n",
       "      <td>0.73</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53270</th>\n",
       "      <td>53270</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>Pratt &amp; Whitney to deliver spare A320neo engin...</td>\n",
       "      <td>Pratt &amp; Whitney will soon begin deliveries of ...</td>\n",
       "      <td>Pratt &amp; Whitney to deliver spare A320neo engin...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>0.95</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53271</th>\n",
       "      <td>53271</td>\n",
       "      <td>3/20/18</td>\n",
       "      <td>UK will always consider ways to improve data l...</td>\n",
       "      <td>Britain will consider any suggestions to give ...</td>\n",
       "      <td>UK will always consider ways to improve data l...</td>\n",
       "      <td>reuters</td>\n",
       "      <td>US Politics</td>\n",
       "      <td>0.94</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53272 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     date                                           headline  \\\n",
       "0          0  7/17/20  Jim Cramer: A better way to invest in the Covi...   \n",
       "1          1  7/17/20     Cramer's lightning round: I would own Teradyne   \n",
       "2          2  7/17/20  Cramer's week ahead: Big week for earnings, ev...   \n",
       "3          3  7/17/20  IQ Capital CEO Keith Bliss says tech and healt...   \n",
       "4          4  7/16/20  Wall Street delivered the 'kind of pullback I'...   \n",
       "...      ...      ...                                                ...   \n",
       "53267  53267  3/20/18  Malaysia says never hired British data firm at...   \n",
       "53268  53268  3/20/18  Prosecutors search Volkswagen headquarters in ...   \n",
       "53269  53269  3/20/18   McDonald's sets greenhouse gas reduction targets   \n",
       "53270  53270  3/20/18  Pratt & Whitney to deliver spare A320neo engin...   \n",
       "53271  53271  3/20/18  UK will always consider ways to improve data l...   \n",
       "\n",
       "                                             description  \\\n",
       "0      \"Mad Money\" host Jim Cramer recommended buying...   \n",
       "1      \"Mad Money\" host Jim Cramer rings the lightnin...   \n",
       "2      \"We'll pay more for the earnings of the non-Co...   \n",
       "3      Keith Bliss, IQ Capital CEO, joins \"Closing Be...   \n",
       "4      \"Look for the stocks of high-quality companies...   \n",
       "...                                                  ...   \n",
       "53267  The Malaysian government and the ruling party ...   \n",
       "53268  German prosecutors said on Tuesday they had se...   \n",
       "53269  McDonald's Corp on Tuesday announced an approv...   \n",
       "53270  Pratt & Whitney will soon begin deliveries of ...   \n",
       "53271  Britain will consider any suggestions to give ...   \n",
       "\n",
       "                                                    text   source  \\\n",
       "0      Jim Cramer: A better way to invest in the Covi...     cnbc   \n",
       "1      Cramer's lightning round: I would own Teradyne...     cnbc   \n",
       "2      Cramer's week ahead: Big week for earnings, ev...     cnbc   \n",
       "3      IQ Capital CEO Keith Bliss says tech and healt...     cnbc   \n",
       "4      Wall Street delivered the 'kind of pullback I'...     cnbc   \n",
       "...                                                  ...      ...   \n",
       "53267  Malaysia says never hired British data firm at...  reuters   \n",
       "53268  Prosecutors search Volkswagen headquarters in ...  reuters   \n",
       "53269  McDonald's sets greenhouse gas reduction targe...  reuters   \n",
       "53270  Pratt & Whitney to deliver spare A320neo engin...  reuters   \n",
       "53271  UK will always consider ways to improve data l...  reuters   \n",
       "\n",
       "          category  category_confidence sentiment  confidence  \n",
       "0       Healthcare                 0.44  Positive        0.85  \n",
       "1       Technology                 0.56  Positive        0.85  \n",
       "2       Healthcare                 0.80  Positive        0.85  \n",
       "3       Technology                 0.63  Positive        0.85  \n",
       "4       Technology                 0.80  Positive        0.85  \n",
       "...            ...                  ...       ...         ...  \n",
       "53267   Technology                 0.60   Neutral        0.60  \n",
       "53268   Automobile                 0.97  Negative        0.85  \n",
       "53269       Energy                 0.73  Positive        0.85  \n",
       "53270     Airlines                 0.95  Positive        0.85  \n",
       "53271  US Politics                 0.94  Positive        0.75  \n",
       "\n",
       "[53272 rows x 10 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_Airlines</th>\n",
       "      <th>sentiment_Automobile</th>\n",
       "      <th>sentiment_Corporate</th>\n",
       "      <th>sentiment_Economy</th>\n",
       "      <th>sentiment_Energy</th>\n",
       "      <th>sentiment_Geo-Political</th>\n",
       "      <th>sentiment_Healthcare</th>\n",
       "      <th>sentiment_Technology</th>\n",
       "      <th>sentiment_US Politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category       date  sentiment_Airlines  sentiment_Automobile  \\\n",
       "0        2017-12-17                 0.0                   NaN   \n",
       "1        2017-12-18                 0.0                  -1.0   \n",
       "2        2017-12-19                -1.0                  -1.0   \n",
       "3        2017-12-20                 NaN                   NaN   \n",
       "4        2017-12-21                 1.0                  -1.0   \n",
       "\n",
       "category  sentiment_Corporate  sentiment_Economy  sentiment_Energy  \\\n",
       "0                   -0.333333                NaN          0.333333   \n",
       "1                   -0.250000               -1.0         -0.333333   \n",
       "2                   -0.500000               -1.0          1.000000   \n",
       "3                   -1.000000                NaN          1.000000   \n",
       "4                    0.000000                NaN               NaN   \n",
       "\n",
       "category  sentiment_Geo-Political  sentiment_Healthcare  sentiment_Technology  \\\n",
       "0                            -1.0                   NaN              0.666667   \n",
       "1                            -1.0                   NaN             -1.000000   \n",
       "2                             NaN                   NaN              0.000000   \n",
       "3                            -1.0                   1.0              0.000000   \n",
       "4                             0.0                  -1.0              1.000000   \n",
       "\n",
       "category  sentiment_US Politics  \n",
       "0                     -0.500000  \n",
       "1                     -0.562500  \n",
       "2                     -0.500000  \n",
       "3                     -0.500000  \n",
       "4                     -0.666667  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure date is datetime (optional)\n",
    "all_news[\"date\"] = pd.to_datetime(all_news[\"date\"])\n",
    "\n",
    "# --- counts per (date, category, sentiment) ---\n",
    "cat_counts = (\n",
    "    all_news\n",
    "    .groupby([\"date\", \"category\", \"sentiment\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)        # columns: Positive / Negative / Neutral (if present)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ensure columns exist even if some sentiment never appears\n",
    "for col in [\"Positive\", \"Negative\", \"Neutral\"]:\n",
    "    if col not in cat_counts.columns:\n",
    "        cat_counts[col] = 0\n",
    "\n",
    "# total news per date & category\n",
    "cat_counts[\"total_cat_news\"] = cat_counts[[\"Positive\", \"Negative\", \"Neutral\"]].sum(axis=1)\n",
    "\n",
    "# avoid division by zero\n",
    "cat_counts[\"total_cat_news\"] = cat_counts[\"total_cat_news\"].replace(0, pd.NA)\n",
    "\n",
    "# category-level sentiment index\n",
    "cat_counts[\"cat_sentiment\"] = (\n",
    "    (cat_counts[\"Positive\"] - cat_counts[\"Negative\"]) / cat_counts[\"total_cat_news\"]\n",
    ")\n",
    "\n",
    "# wide format: one column per category\n",
    "cat_sent_wide = (\n",
    "    cat_counts\n",
    "    .pivot(index=\"date\", columns=\"category\", values=\"cat_sentiment\")\n",
    "    .add_prefix(\"sentiment_\")      # e.g. sentiment_Healthcare, sentiment_Technology\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cat_sent_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment       date  overall_sentiment\n",
       "0         2017-12-17              -0.15\n",
       "1         2017-12-18              -0.50\n",
       "2         2017-12-19              -0.40\n",
       "3         2017-12-20              -0.45\n",
       "4         2017-12-21              -0.35"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# counts per (date, sentiment)\n",
    "daily_sent = (\n",
    "    all_news\n",
    "    .groupby([\"date\", \"sentiment\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)        # columns: Positive / Negative / Neutral\n",
    ")\n",
    "\n",
    "for col in [\"Positive\", \"Negative\", \"Neutral\"]:\n",
    "    if col not in daily_sent.columns:\n",
    "        daily_sent[col] = 0\n",
    "\n",
    "daily_sent[\"total_news\"] = daily_sent[[\"Positive\", \"Negative\", \"Neutral\"]].sum(axis=1)\n",
    "daily_sent[\"total_news\"] = daily_sent[\"total_news\"].replace(0, pd.NA)\n",
    "\n",
    "daily_sent[\"overall_sentiment\"] = (\n",
    "    (daily_sent[\"Positive\"] - daily_sent[\"Negative\"]) / daily_sent[\"total_news\"]\n",
    ")\n",
    "\n",
    "daily_sent = daily_sent[[\"overall_sentiment\"]].reset_index()\n",
    "\n",
    "daily_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_Airlines</th>\n",
       "      <th>sentiment_Automobile</th>\n",
       "      <th>sentiment_Corporate</th>\n",
       "      <th>sentiment_Economy</th>\n",
       "      <th>sentiment_Energy</th>\n",
       "      <th>sentiment_Geo-Political</th>\n",
       "      <th>sentiment_Healthcare</th>\n",
       "      <th>sentiment_Technology</th>\n",
       "      <th>sentiment_US Politics</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sentiment_Airlines  sentiment_Automobile  sentiment_Corporate  \\\n",
       "0 2017-12-17                 0.0                   NaN            -0.333333   \n",
       "1 2017-12-18                 0.0                  -1.0            -0.250000   \n",
       "2 2017-12-19                -1.0                  -1.0            -0.500000   \n",
       "3 2017-12-20                 NaN                   NaN            -1.000000   \n",
       "4 2017-12-21                 1.0                  -1.0             0.000000   \n",
       "\n",
       "   sentiment_Economy  sentiment_Energy  sentiment_Geo-Political  \\\n",
       "0                NaN          0.333333                     -1.0   \n",
       "1               -1.0         -0.333333                     -1.0   \n",
       "2               -1.0          1.000000                      NaN   \n",
       "3                NaN          1.000000                     -1.0   \n",
       "4                NaN               NaN                      0.0   \n",
       "\n",
       "   sentiment_Healthcare  sentiment_Technology  sentiment_US Politics  \\\n",
       "0                   NaN              0.666667              -0.500000   \n",
       "1                   NaN             -1.000000              -0.562500   \n",
       "2                   NaN              0.000000              -0.500000   \n",
       "3                   1.0              0.000000              -0.500000   \n",
       "4                  -1.0              1.000000              -0.666667   \n",
       "\n",
       "   overall_sentiment  \n",
       "0              -0.15  \n",
       "1              -0.50  \n",
       "2              -0.40  \n",
       "3              -0.45  \n",
       "4              -0.35  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_daily = cat_sent_wide.merge(daily_sent, on=\"date\", how=\"left\")\n",
    "\n",
    "final_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_Airlines</th>\n",
       "      <th>sentiment_Automobile</th>\n",
       "      <th>sentiment_Corporate</th>\n",
       "      <th>sentiment_Economy</th>\n",
       "      <th>sentiment_Energy</th>\n",
       "      <th>sentiment_Geo-Political</th>\n",
       "      <th>sentiment_Healthcare</th>\n",
       "      <th>sentiment_Technology</th>\n",
       "      <th>sentiment_US Politics</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sentiment_Airlines  sentiment_Automobile  sentiment_Corporate  \\\n",
       "0 2017-12-17                 0.0                   0.0            -0.333333   \n",
       "1 2017-12-18                 0.0                  -1.0            -0.250000   \n",
       "2 2017-12-19                -1.0                  -1.0            -0.500000   \n",
       "3 2017-12-20                 0.0                   0.0            -1.000000   \n",
       "4 2017-12-21                 1.0                  -1.0             0.000000   \n",
       "\n",
       "   sentiment_Economy  sentiment_Energy  sentiment_Geo-Political  \\\n",
       "0                0.0          0.333333                     -1.0   \n",
       "1               -1.0         -0.333333                     -1.0   \n",
       "2               -1.0          1.000000                      0.0   \n",
       "3                0.0          1.000000                     -1.0   \n",
       "4                0.0          0.000000                      0.0   \n",
       "\n",
       "   sentiment_Healthcare  sentiment_Technology  sentiment_US Politics  \\\n",
       "0                   0.0              0.666667              -0.500000   \n",
       "1                   0.0             -1.000000              -0.562500   \n",
       "2                   0.0              0.000000              -0.500000   \n",
       "3                   1.0              0.000000              -0.500000   \n",
       "4                  -1.0              1.000000              -0.666667   \n",
       "\n",
       "   overall_sentiment  \n",
       "0              -0.15  \n",
       "1              -0.50  \n",
       "2              -0.40  \n",
       "3              -0.45  \n",
       "4              -0.35  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_daily_filled = final_daily.copy()\n",
    "\n",
    "# All sentiment columns (category-level) + overall\n",
    "sent_cols = [c for c in final_daily_filled.columns if c.startswith(\"sentiment_\")]\n",
    "sent_cols.append(\"overall_sentiment\")\n",
    "\n",
    "for col in sent_cols:\n",
    "    if col in final_daily_filled.columns:\n",
    "        final_daily_filled[col] = final_daily_filled[col].fillna(0.0)\n",
    "\n",
    "final_daily_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931 entries, 0 to 930\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   date                     931 non-null    datetime64[ns]\n",
      " 1   sentiment_Airlines       931 non-null    float64       \n",
      " 2   sentiment_Automobile     931 non-null    float64       \n",
      " 3   sentiment_Corporate      931 non-null    float64       \n",
      " 4   sentiment_Economy        931 non-null    float64       \n",
      " 5   sentiment_Energy         931 non-null    float64       \n",
      " 6   sentiment_Geo-Political  931 non-null    float64       \n",
      " 7   sentiment_Healthcare     931 non-null    float64       \n",
      " 8   sentiment_Technology     931 non-null    float64       \n",
      " 9   sentiment_US Politics    931 non-null    float64       \n",
      " 10  overall_sentiment        931 non-null    float64       \n",
      "dtypes: datetime64[ns](1), float64(10)\n",
      "memory usage: 80.1 KB\n"
     ]
    }
   ],
   "source": [
    "final_daily_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df_merged = model_df_merged.merge(\n",
    "    final_daily_filled,\n",
    "    on=\"date\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# In case some dates exist in returns but not in news at all:\n",
    "sent_cols_all = [c for c in model_df_merged.columns if c.startswith(\"sentiment_\")] + [\"overall_sentiment\"]\n",
    "for col in sent_cols_all:\n",
    "    if col in model_df_merged.columns:\n",
    "        model_df_merged[col] = model_df_merged[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sentiment_compound_mean</th>\n",
       "      <th>sentiment_compound_std</th>\n",
       "      <th>sentiment_compound_min</th>\n",
       "      <th>sentiment_compound_max</th>\n",
       "      <th>sentiment_pos_mean</th>\n",
       "      <th>sentiment_neg_mean</th>\n",
       "      <th>sentiment_neu_mean</th>\n",
       "      <th>num_news</th>\n",
       "      <th>return_t</th>\n",
       "      <th>...</th>\n",
       "      <th>sentiment_Airlines</th>\n",
       "      <th>sentiment_Automobile</th>\n",
       "      <th>sentiment_Corporate</th>\n",
       "      <th>sentiment_Economy</th>\n",
       "      <th>sentiment_Energy</th>\n",
       "      <th>sentiment_Geo-Political</th>\n",
       "      <th>sentiment_Healthcare</th>\n",
       "      <th>sentiment_Technology</th>\n",
       "      <th>sentiment_US Politics</th>\n",
       "      <th>overall_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>-0.110590</td>\n",
       "      <td>0.476690</td>\n",
       "      <td>-0.8807</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.104625</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>40</td>\n",
       "      <td>0.536281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.562500</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-12-19</td>\n",
       "      <td>-0.261770</td>\n",
       "      <td>0.481266</td>\n",
       "      <td>-0.8750</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.026950</td>\n",
       "      <td>0.120250</td>\n",
       "      <td>0.852800</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.323027</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>0.031795</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>-0.9698</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.068950</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.082789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>0.077030</td>\n",
       "      <td>0.462032</td>\n",
       "      <td>-0.6808</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>0.086550</td>\n",
       "      <td>0.799550</td>\n",
       "      <td>20</td>\n",
       "      <td>0.198566</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>0.037161</td>\n",
       "      <td>0.530048</td>\n",
       "      <td>-0.8481</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>0.078609</td>\n",
       "      <td>0.811913</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.045817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sentiment_compound_mean  sentiment_compound_std  \\\n",
       "0 2017-12-18                -0.110590                0.476690   \n",
       "1 2017-12-19                -0.261770                0.481266   \n",
       "2 2017-12-20                 0.031795                0.498608   \n",
       "3 2017-12-21                 0.077030                0.462032   \n",
       "4 2017-12-22                 0.037161                0.530048   \n",
       "\n",
       "   sentiment_compound_min  sentiment_compound_max  sentiment_pos_mean  \\\n",
       "0                 -0.8807                  0.8402            0.061600   \n",
       "1                 -0.8750                  0.6759            0.026950   \n",
       "2                 -0.9698                  0.8750            0.068950   \n",
       "3                 -0.6808                  0.7650            0.113900   \n",
       "4                 -0.8481                  0.8750            0.109478   \n",
       "\n",
       "   sentiment_neg_mean  sentiment_neu_mean  num_news  return_t  ...  \\\n",
       "0            0.104625            0.833800        40  0.536281  ...   \n",
       "1            0.120250            0.852800        20 -0.323027  ...   \n",
       "2            0.078900            0.852150        20 -0.082789  ...   \n",
       "3            0.086550            0.799550        20  0.198566  ...   \n",
       "4            0.078609            0.811913        23 -0.045817  ...   \n",
       "\n",
       "   sentiment_Airlines sentiment_Automobile sentiment_Corporate  \\\n",
       "0                 0.0                 -1.0           -0.250000   \n",
       "1                -1.0                 -1.0           -0.500000   \n",
       "2                 0.0                  0.0           -1.000000   \n",
       "3                 1.0                 -1.0            0.000000   \n",
       "4                 0.0                  0.0           -0.555556   \n",
       "\n",
       "   sentiment_Economy  sentiment_Energy  sentiment_Geo-Political  \\\n",
       "0               -1.0         -0.333333                     -1.0   \n",
       "1               -1.0          1.000000                      0.0   \n",
       "2                0.0          1.000000                     -1.0   \n",
       "3                0.0          0.000000                      0.0   \n",
       "4               -1.0          1.000000                      0.0   \n",
       "\n",
       "   sentiment_Healthcare  sentiment_Technology  sentiment_US Politics  \\\n",
       "0                   0.0                  -1.0              -0.562500   \n",
       "1                   0.0                   0.0              -0.500000   \n",
       "2                   1.0                   0.0              -0.500000   \n",
       "3                  -1.0                   1.0              -0.666667   \n",
       "4                  -1.0                   0.6               0.600000   \n",
       "\n",
       "   overall_sentiment  \n",
       "0          -0.500000  \n",
       "1          -0.400000  \n",
       "2          -0.450000  \n",
       "3          -0.350000  \n",
       "4           0.043478  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'sentiment_compound_mean', 'sentiment_compound_std',\n",
       "       'sentiment_compound_min', 'sentiment_compound_max',\n",
       "       'sentiment_pos_mean', 'sentiment_neg_mean', 'sentiment_neu_mean',\n",
       "       'num_news', 'return_t', 'return_t_plus_1', 'return_bucket',\n",
       "       'direction_binary', 'sentiment_score', 'net_sentiment',\n",
       "       'sentiment_Airlines', 'sentiment_Automobile', 'sentiment_Corporate',\n",
       "       'sentiment_Economy', 'sentiment_Energy', 'sentiment_Geo-Political',\n",
       "       'sentiment_Healthcare', 'sentiment_Technology', 'sentiment_US Politics',\n",
       "       'overall_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_merged.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML to refine the algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe\n",
    "df = model_df_merged.copy()\n",
    "\n",
    "# Make sure the date is sorted\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "# drop rows with missing targets if any\n",
    "targets = [\"return_t_plus_1\", \"return_bucket\", \"direction_binary\"]\n",
    "df = df.dropna(subset=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (452, 25) Test size: (195, 25)\n",
      "Train period: 2017-12-18 00:00:00 -> 2019-10-08 00:00:00\n",
      "Test period: 2019-10-09 00:00:00 → 2020-07-17 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Time-based train/test split (e.g. 70/30)\n",
    "n = len(df)\n",
    "split_idx = int(n * 0.7)\n",
    "\n",
    "train_df = df.iloc[:split_idx].reset_index(drop=True)\n",
    "test_df  = df.iloc[split_idx:].reset_index(drop=True)\n",
    "\n",
    "print(\"Train size:\", train_df.shape, \"Test size:\", test_df.shape)\n",
    "print(\"Train period:\", model_df_sorted['date'].iloc[0], '->', model_df_sorted['date'].iloc[split_idx-1])\n",
    "print(\"Test period:\", model_df_sorted[\"date\"].iloc[split_idx], \"→\", model_df_sorted[\"date\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature set up\n",
    "feature_cols_all = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "    \"sentiment_score\",\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]\n",
    "\n",
    "feature_cols_vader = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "]\n",
    "\n",
    "feature_cols_genai = [\n",
    "    \"sentiment_score\",\n",
    "]\n",
    "\n",
    "feature_cols_sector = [\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== REGRESSION – return_t_plus_1 – All sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape         (452, 19)\n",
      "4        Transformed data shape         (452, 19)\n",
      "5   Transformed train set shape         (316, 19)\n",
      "6    Transformed test set shape         (136, 19)\n",
      "7              Numeric features                18\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              d650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model          MAE           MSE  \\\n",
      "lasso                    Lasso Regression       0.7166  1.037300e+00   \n",
      "llar         Lasso Least Angle Regression       0.7166  1.037300e+00   \n",
      "dummy                     Dummy Regressor       0.7166  1.037300e+00   \n",
      "en                            Elastic Net       0.7166  1.037300e+00   \n",
      "br                         Bayesian Ridge       0.7174  1.038600e+00   \n",
      "omp           Orthogonal Matching Pursuit       0.7328  1.071900e+00   \n",
      "huber                     Huber Regressor       0.7501  1.087100e+00   \n",
      "ridge                    Ridge Regression       0.7603  1.095700e+00   \n",
      "et                  Extra Trees Regressor       0.7689  1.135800e+00   \n",
      "rf                Random Forest Regressor       0.7701  1.153700e+00   \n",
      "lr                      Linear Regression       0.7720  1.104500e+00   \n",
      "catboost               CatBoost Regressor       0.7961  1.208900e+00   \n",
      "knn                 K Neighbors Regressor       0.8075  1.201700e+00   \n",
      "ada                    AdaBoost Regressor       0.8204  1.271000e+00   \n",
      "lightgbm  Light Gradient Boosting Machine       0.8376  1.266800e+00   \n",
      "gbr           Gradient Boosting Regressor       0.8416  1.287000e+00   \n",
      "xgboost         Extreme Gradient Boosting       0.8527  1.350500e+00   \n",
      "dt                Decision Tree Regressor       1.0498  2.033500e+00   \n",
      "par          Passive Aggressive Regressor       1.1834  2.155700e+00   \n",
      "lar                Least Angle Regression  288904.2132  1.497891e+12   \n",
      "\n",
      "                 RMSE            R2   RMSLE          MAPE  TT (Sec)  \n",
      "lasso          1.0001 -4.830000e-02  0.5662  1.243900e+00     0.006  \n",
      "llar           1.0001 -4.830000e-02  0.5662  1.243900e+00     0.006  \n",
      "dummy          1.0001 -4.830000e-02  0.5662  1.243900e+00     0.005  \n",
      "en             1.0001 -4.830000e-02  0.5662  1.243900e+00     0.006  \n",
      "br             1.0007 -4.940000e-02  0.5663  1.252700e+00     0.006  \n",
      "omp            1.0173 -8.560000e-02  0.5337  1.615200e+00     0.006  \n",
      "huber          1.0280 -1.187000e-01  0.4666  3.047500e+00     0.012  \n",
      "ridge          1.0301 -1.181000e-01  0.4993  1.962000e+00     0.006  \n",
      "et             1.0460 -1.529000e-01  0.4659  2.522200e+00     0.079  \n",
      "rf             1.0551 -1.702000e-01  0.4702  3.187100e+00     0.158  \n",
      "lr             1.0352 -1.368000e-01  0.4627  3.209800e+00     0.005  \n",
      "catboost       1.0813 -2.347000e-01  0.4472  3.475900e+00     1.198  \n",
      "knn            1.0766 -2.222000e-01  0.4369  4.866300e+00     0.006  \n",
      "ada            1.1050 -2.852000e-01  0.4283  3.290100e+00     0.043  \n",
      "lightgbm       1.1040 -2.990000e-01  0.4243  6.597200e+00     0.016  \n",
      "gbr            1.1196 -3.371000e-01  0.4307  3.391900e+00     0.073  \n",
      "xgboost        1.1396 -3.772000e-01  0.4319  9.320000e+00     0.058  \n",
      "dt             1.4143 -1.217200e+00  0.4887  5.674900e+00     0.008  \n",
      "par            1.4356 -1.249800e+00  0.4600  7.304100e+00     0.006  \n",
      "lar       387035.7993 -2.150486e+12  2.3026  5.944766e+06     0.006  \n",
      "Best model: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,\n",
      "      precompute=False, random_state=42, selection='cyclic', tol=0.0001,\n",
      "      warm_start=False)\n",
      "\n",
      "===== REGRESSION – return_t_plus_1 – VADER sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape          (452, 8)\n",
      "4        Transformed data shape          (452, 8)\n",
      "5   Transformed train set shape          (316, 8)\n",
      "6    Transformed test set shape          (136, 8)\n",
      "7              Numeric features                 7\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              ca74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE       MSE    RMSE        R2  \\\n",
      "lasso                    Lasso Regression  0.7166    1.0373  1.0001   -0.0483   \n",
      "llar         Lasso Least Angle Regression  0.7166    1.0373  1.0001   -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166    1.0373  1.0001   -0.0483   \n",
      "en                            Elastic Net  0.7166    1.0373  1.0001   -0.0483   \n",
      "ridge                    Ridge Regression  0.7184    1.0391  1.0011   -0.0506   \n",
      "huber                     Huber Regressor  0.7202    1.0314  0.9995   -0.0535   \n",
      "br                         Bayesian Ridge  0.7219    1.0511  1.0069   -0.0630   \n",
      "omp           Orthogonal Matching Pursuit  0.7273    1.0540  1.0080   -0.0647   \n",
      "lr                      Linear Regression  0.7328    1.0419  1.0044   -0.0652   \n",
      "rf                Random Forest Regressor  0.7670    1.1206  1.0399   -0.1347   \n",
      "et                  Extra Trees Regressor  0.7685    1.1241  1.0390   -0.1301   \n",
      "catboost               CatBoost Regressor  0.8030    1.2032  1.0775   -0.2219   \n",
      "ada                    AdaBoost Regressor  0.8103    1.2431  1.0946   -0.2624   \n",
      "gbr           Gradient Boosting Regressor  0.8104    1.2318  1.0881   -0.2413   \n",
      "lightgbm  Light Gradient Boosting Machine  0.8121    1.1888  1.0688   -0.2067   \n",
      "knn                 K Neighbors Regressor  0.8209    1.2350  1.0931   -0.2651   \n",
      "xgboost         Extreme Gradient Boosting  0.8728    1.3660  1.1461   -0.4032   \n",
      "dt                Decision Tree Regressor  1.1265    2.3416  1.5025   -1.4353   \n",
      "par          Passive Aggressive Regressor  1.5540    3.1349  1.7389   -2.4726   \n",
      "lar                Least Angle Regression  6.0936  167.5897  7.6535 -233.7604   \n",
      "\n",
      "           RMSLE     MAPE  TT (Sec)  \n",
      "lasso     0.5662   1.2439     0.005  \n",
      "llar      0.5662   1.2439     0.004  \n",
      "dummy     0.5662   1.2439     0.003  \n",
      "en        0.5662   1.2439     0.005  \n",
      "ridge     0.5479   1.3684     0.004  \n",
      "huber     0.4833   3.0933     0.009  \n",
      "br        0.5527   1.2930     0.005  \n",
      "omp       0.5471   1.2963     0.004  \n",
      "lr        0.4698   3.1104     0.004  \n",
      "rf        0.4626   3.3747     0.095  \n",
      "et        0.4597   3.7017     0.053  \n",
      "catboost  0.4473   5.1121     0.724  \n",
      "ada       0.4350   3.0448     0.031  \n",
      "gbr       0.4551   4.9332     0.045  \n",
      "lightgbm  0.4299   4.9094     0.017  \n",
      "knn       0.4343   6.4090     0.005  \n",
      "xgboost   0.4432  11.2855     0.044  \n",
      "dt        0.4819  13.6424     0.005  \n",
      "par       0.5244  19.8148     0.005  \n",
      "lar       1.0555  43.1127     0.005  \n",
      "Best model: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,\n",
      "      precompute=False, random_state=42, selection='cyclic', tol=0.0001,\n",
      "      warm_start=False)\n",
      "\n",
      "===== REGRESSION – return_t_plus_1 – GenAI sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape          (452, 2)\n",
      "4        Transformed data shape          (452, 2)\n",
      "5   Transformed train set shape          (316, 2)\n",
      "6    Transformed test set shape          (136, 2)\n",
      "7              Numeric features                 1\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              c55b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE     MSE    RMSE      R2  \\\n",
      "huber                     Huber Regressor  0.7159  1.0444  1.0060 -0.0660   \n",
      "llar         Lasso Least Angle Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166  1.0373  1.0001 -0.0483   \n",
      "lasso                    Lasso Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "en                            Elastic Net  0.7166  1.0373  1.0001 -0.0483   \n",
      "br                         Bayesian Ridge  0.7190  1.0475  1.0057 -0.0611   \n",
      "ridge                    Ridge Regression  0.7192  1.0444  1.0048 -0.0605   \n",
      "omp           Orthogonal Matching Pursuit  0.7203  1.0461  1.0059 -0.0633   \n",
      "lr                      Linear Regression  0.7203  1.0461  1.0059 -0.0633   \n",
      "lar                Least Angle Regression  0.7203  1.0461  1.0059 -0.0633   \n",
      "lightgbm  Light Gradient Boosting Machine  0.7583  1.1292  1.0482 -0.1617   \n",
      "gbr           Gradient Boosting Regressor  0.8046  1.3016  1.1184 -0.3168   \n",
      "ada                    AdaBoost Regressor  0.8072  1.1662  1.0626 -0.1916   \n",
      "catboost               CatBoost Regressor  0.8104  1.3189  1.1221 -0.3160   \n",
      "knn                 K Neighbors Regressor  0.8170  1.2846  1.1162 -0.3193   \n",
      "rf                Random Forest Regressor  0.8905  1.5242  1.2137 -0.5605   \n",
      "et                  Extra Trees Regressor  0.9617  1.6704  1.2790 -0.7681   \n",
      "xgboost         Extreme Gradient Boosting  1.0002  1.8205  1.3432 -1.0355   \n",
      "dt                Decision Tree Regressor  1.0387  1.9661  1.3792 -1.0314   \n",
      "par          Passive Aggressive Regressor  1.1311  2.0791  1.3765 -1.1128   \n",
      "\n",
      "           RMSLE    MAPE  TT (Sec)  \n",
      "huber     0.5156  1.6747     0.004  \n",
      "llar      0.5662  1.2439     0.004  \n",
      "dummy     0.5662  1.2439     0.003  \n",
      "lasso     0.5662  1.2439     0.004  \n",
      "en        0.5662  1.2439     0.004  \n",
      "br        0.5552  1.1076     0.004  \n",
      "ridge     0.5462  1.2884     0.004  \n",
      "omp       0.5423  1.3696     0.004  \n",
      "lr        0.5423  1.3696     0.004  \n",
      "lar       0.5423  1.3696     0.004  \n",
      "lightgbm  0.4558  2.5856     0.010  \n",
      "gbr       0.4790  2.6152     0.019  \n",
      "ada       0.4643  3.3545     0.011  \n",
      "catboost  0.4680  3.1945     0.143  \n",
      "knn       0.4286  5.3585     0.004  \n",
      "rf        0.4438  4.1866     0.045  \n",
      "et        0.4575  5.0066     0.032  \n",
      "xgboost   0.4878  9.1152     0.013  \n",
      "dt        0.4843  8.7181     0.004  \n",
      "par       0.4494  8.0333     0.004  \n",
      "Best model: HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,\n",
      "               tol=1e-05, warm_start=False)\n",
      "\n",
      "===== REGRESSION – return_t_plus_1 – Sectoral sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape         (452, 11)\n",
      "4        Transformed data shape         (452, 11)\n",
      "5   Transformed train set shape         (316, 11)\n",
      "6    Transformed test set shape         (136, 11)\n",
      "7              Numeric features                10\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              2f41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE     MSE    RMSE      R2  \\\n",
      "lasso                    Lasso Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "llar         Lasso Least Angle Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166  1.0373  1.0001 -0.0483   \n",
      "en                            Elastic Net  0.7166  1.0373  1.0001 -0.0483   \n",
      "br                         Bayesian Ridge  0.7174  1.0387  1.0007 -0.0495   \n",
      "omp           Orthogonal Matching Pursuit  0.7328  1.0719  1.0173 -0.0856   \n",
      "huber                     Huber Regressor  0.7346  1.0726  1.0194 -0.0948   \n",
      "ridge                    Ridge Regression  0.7563  1.0903  1.0270 -0.1096   \n",
      "lr                      Linear Regression  0.7585  1.0928  1.0283 -0.1127   \n",
      "lar                Least Angle Regression  0.7585  1.0928  1.0283 -0.1127   \n",
      "rf                Random Forest Regressor  0.7841  1.1709  1.0668 -0.2075   \n",
      "et                  Extra Trees Regressor  0.7967  1.1898  1.0743 -0.2245   \n",
      "knn                 K Neighbors Regressor  0.8033  1.1952  1.0758 -0.2230   \n",
      "catboost               CatBoost Regressor  0.8319  1.2744  1.1121 -0.3175   \n",
      "ada                    AdaBoost Regressor  0.8357  1.2265  1.0895 -0.2530   \n",
      "lightgbm  Light Gradient Boosting Machine  0.8500  1.2878  1.1163 -0.3222   \n",
      "gbr           Gradient Boosting Regressor  0.8622  1.3155  1.1337 -0.3746   \n",
      "xgboost         Extreme Gradient Boosting  0.9147  1.4833  1.2037 -0.5583   \n",
      "dt                Decision Tree Regressor  1.1308  2.2960  1.4975 -1.4374   \n",
      "par          Passive Aggressive Regressor  1.1606  2.2217  1.4654 -1.3043   \n",
      "\n",
      "           RMSLE     MAPE  TT (Sec)  \n",
      "lasso     0.5662   1.2439     0.005  \n",
      "llar      0.5662   1.2439     0.005  \n",
      "dummy     0.5662   1.2439     0.004  \n",
      "en        0.5662   1.2439     0.005  \n",
      "br        0.5663   1.2568     0.005  \n",
      "omp       0.5337   1.6152     0.005  \n",
      "huber     0.5128   1.7057     0.007  \n",
      "ridge     0.5107   1.8922     0.005  \n",
      "lr        0.5083   1.9238     0.005  \n",
      "lar       0.5083   1.9238     0.005  \n",
      "rf        0.4720   2.3788     0.095  \n",
      "et        0.4748   2.4905     0.060  \n",
      "knn       0.4432   4.8580     0.005  \n",
      "catboost  0.4429   3.0434     0.426  \n",
      "ada       0.4572   3.0085     0.030  \n",
      "lightgbm  0.4491   3.6969     0.013  \n",
      "gbr       0.4602   3.8070     0.043  \n",
      "xgboost   0.4455   3.8660     0.032  \n",
      "dt        0.4874  14.6212     0.006  \n",
      "par       0.4648   6.9747     0.005  \n",
      "Best model: Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000, positive=False,\n",
      "      precompute=False, random_state=42, selection='cyclic', tol=0.0001,\n",
      "      warm_start=False)\n",
      "\n",
      "===== CLASSIFICATION – return_bucket – All sentiment =====\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                          (452, 19)  \n",
      "5                                          (452, 19)  \n",
      "6                                          (316, 19)  \n",
      "7                                          (136, 19)  \n",
      "8                                                 18  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              5e12  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "nb                            Naive Bayes    0.3075  0.5898  0.3075  0.3135   \n",
      "et                 Extra Trees Classifier    0.2979  0.5552  0.2979  0.2863   \n",
      "lda          Linear Discriminant Analysis    0.2880  0.0000  0.2880  0.2761   \n",
      "xgboost         Extreme Gradient Boosting    0.2787  0.5074  0.2787  0.2816   \n",
      "catboost              CatBoost Classifier    0.2787  0.5148  0.2787  0.2813   \n",
      "gbc          Gradient Boosting Classifier    0.2784  0.0000  0.2784  0.2808   \n",
      "rf               Random Forest Classifier    0.2783  0.5373  0.2783  0.2751   \n",
      "svm                   SVM - Linear Kernel    0.2755  0.0000  0.2755  0.1773   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2752  0.5111  0.2752  0.2824   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "ridge                    Ridge Classifier    0.2689  0.0000  0.2689  0.2398   \n",
      "lr                    Logistic Regression    0.2659  0.0000  0.2659  0.2429   \n",
      "ada                  Ada Boost Classifier    0.2625  0.0000  0.2625  0.2726   \n",
      "qda       Quadratic Discriminant Analysis    0.2560  0.0000  0.2560  0.2698   \n",
      "knn                K Neighbors Classifier    0.2212  0.5171  0.2212  0.2252   \n",
      "dt               Decision Tree Classifier    0.1999  0.4670  0.1999  0.2053   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "nb        0.2832  0.0776  0.0822     0.010  \n",
      "et        0.2781  0.0549  0.0586     0.056  \n",
      "lda       0.2759  0.0461  0.0469     0.009  \n",
      "xgboost   0.2695  0.0323  0.0333     0.091  \n",
      "catboost  0.2697  0.0307  0.0313     3.922  \n",
      "gbc       0.2666  0.0303  0.0317     0.331  \n",
      "rf        0.2640  0.0279  0.0287     0.078  \n",
      "svm       0.1794  0.0217  0.0269     0.012  \n",
      "lightgbm  0.2683  0.0274  0.0293     0.050  \n",
      "dummy     0.1189  0.0000  0.0000     0.009  \n",
      "ridge     0.2442  0.0139  0.0147     0.010  \n",
      "lr        0.2431  0.0102  0.0109     0.014  \n",
      "ada       0.2580  0.0103  0.0107     0.047  \n",
      "qda       0.2403  0.0095  0.0113     0.010  \n",
      "knn       0.2078 -0.0344 -0.0349     0.016  \n",
      "dt        0.1976 -0.0665 -0.0674     0.012  \n",
      "Best model: GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      "===== CLASSIFICATION – return_bucket – VADER sentiment =====\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                           (452, 8)  \n",
      "5                                           (452, 8)  \n",
      "6                                           (316, 8)  \n",
      "7                                           (136, 8)  \n",
      "8                                                  7  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              0e5c  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lr                    Logistic Regression    0.3134  0.0000  0.3134  0.1717   \n",
      "knn                K Neighbors Classifier    0.3068  0.5430  0.3068  0.3091   \n",
      "lda          Linear Discriminant Analysis    0.3037  0.0000  0.3037  0.3028   \n",
      "et                 Extra Trees Classifier    0.2921  0.5179  0.2921  0.2853   \n",
      "ada                  Ada Boost Classifier    0.2911  0.0000  0.2911  0.2941   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2887  0.5164  0.2887  0.2867   \n",
      "ridge                    Ridge Classifier    0.2879  0.0000  0.2879  0.1943   \n",
      "rf               Random Forest Classifier    0.2827  0.5212  0.2827  0.2770   \n",
      "xgboost         Extreme Gradient Boosting    0.2825  0.5199  0.2825  0.2713   \n",
      "svm                   SVM - Linear Kernel    0.2821  0.0000  0.2821  0.1534   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "catboost              CatBoost Classifier    0.2731  0.5196  0.2731  0.2816   \n",
      "gbc          Gradient Boosting Classifier    0.2727  0.0000  0.2727  0.2723   \n",
      "nb                            Naive Bayes    0.2694  0.5588  0.2694  0.2839   \n",
      "qda       Quadratic Discriminant Analysis    0.2656  0.0000  0.2656  0.2561   \n",
      "dt               Decision Tree Classifier    0.2191  0.4769  0.2191  0.2103   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lr        0.2183  0.0602  0.0744     0.011  \n",
      "knn       0.2994  0.0783  0.0796     0.010  \n",
      "lda       0.2952  0.0642  0.0655     0.008  \n",
      "et        0.2808  0.0532  0.0553     0.051  \n",
      "ada       0.2862  0.0524  0.0538     0.040  \n",
      "lightgbm  0.2754  0.0470  0.0495     0.044  \n",
      "ridge     0.2104  0.0274  0.0340     0.009  \n",
      "rf        0.2725  0.0383  0.0400     0.070  \n",
      "xgboost   0.2692  0.0375  0.0381     0.078  \n",
      "svm       0.1565  0.0173  0.0392     0.010  \n",
      "dummy     0.1189  0.0000  0.0000     0.009  \n",
      "catboost  0.2667  0.0253  0.0265     2.333  \n",
      "gbc       0.2670  0.0264  0.0264     0.215  \n",
      "nb        0.2489  0.0314  0.0322     0.010  \n",
      "qda       0.2381  0.0236  0.0253     0.008  \n",
      "dt        0.2123 -0.0464 -0.0471     0.010  \n",
      "Best model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "===== CLASSIFICATION – return_bucket – GenAI sentiment =====\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                           (452, 2)  \n",
      "5                                           (452, 2)  \n",
      "6                                           (316, 2)  \n",
      "7                                           (136, 2)  \n",
      "8                                                  1  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              0c88  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "ridge                    Ridge Classifier    0.3324  0.0000  0.3324  0.1942   \n",
      "lda          Linear Discriminant Analysis    0.3323  0.0000  0.3323  0.1939   \n",
      "lr                    Logistic Regression    0.3258  0.0000  0.3258  0.1803   \n",
      "nb                            Naive Bayes    0.2944  0.5778  0.2944  0.2358   \n",
      "qda       Quadratic Discriminant Analysis    0.2944  0.0000  0.2944  0.2358   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2817  0.5343  0.2817  0.2911   \n",
      "knn                K Neighbors Classifier    0.2789  0.5701  0.2789  0.2752   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "xgboost         Extreme Gradient Boosting    0.2600  0.5401  0.2600  0.2681   \n",
      "gbc          Gradient Boosting Classifier    0.2598  0.0000  0.2598  0.2608   \n",
      "rf               Random Forest Classifier    0.2597  0.5399  0.2597  0.2586   \n",
      "catboost              CatBoost Classifier    0.2595  0.5334  0.2595  0.2628   \n",
      "dt               Decision Tree Classifier    0.2470  0.4934  0.2470  0.2409   \n",
      "svm                   SVM - Linear Kernel    0.2440  0.0000  0.2440  0.0897   \n",
      "ada                  Ada Boost Classifier    0.2410  0.0000  0.2410  0.2455   \n",
      "et                 Extra Trees Classifier    0.2311  0.4968  0.2311  0.2320   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "ridge     0.2382  0.0848  0.1015     0.009  \n",
      "lda       0.2379  0.0846  0.1015     0.008  \n",
      "lr        0.2301  0.0755  0.0912     0.009  \n",
      "nb        0.2341  0.0423  0.0517     0.009  \n",
      "qda       0.2341  0.0423  0.0517     0.009  \n",
      "lightgbm  0.2723  0.0365  0.0376     0.034  \n",
      "knn       0.2707  0.0401  0.0406     0.011  \n",
      "dummy     0.1189  0.0000  0.0000     0.008  \n",
      "xgboost   0.2547  0.0114  0.0116     0.042  \n",
      "gbc       0.2486  0.0086  0.0088     0.120  \n",
      "rf        0.2516  0.0099  0.0098     0.062  \n",
      "catboost  0.2524  0.0084  0.0084     0.434  \n",
      "dt        0.2372 -0.0054 -0.0059     0.010  \n",
      "svm       0.1118  0.0100  0.0106     0.009  \n",
      "ada       0.2336 -0.0212 -0.0222     0.037  \n",
      "et        0.2247 -0.0260 -0.0266     0.050  \n",
      "Best model: RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, positive=False, random_state=42, solver='auto',\n",
      "                tol=0.0001)\n",
      "\n",
      "===== CLASSIFICATION – return_bucket – Sectoral sentiment =====\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                          (452, 11)  \n",
      "5                                          (452, 11)  \n",
      "6                                          (316, 11)  \n",
      "7                                          (136, 11)  \n",
      "8                                                 10  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              83f6  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.2973  0.5379  0.2973  0.3141   \n",
      "gbc          Gradient Boosting Classifier    0.2973  0.0000  0.2973  0.3007   \n",
      "qda       Quadratic Discriminant Analysis    0.2820  0.0000  0.2820  0.2951   \n",
      "nb                            Naive Bayes    0.2787  0.5588  0.2787  0.2932   \n",
      "catboost              CatBoost Classifier    0.2784  0.5051  0.2784  0.2842   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2749  0.5135  0.2749  0.2619   \n",
      "xgboost         Extreme Gradient Boosting    0.2693  0.5150  0.2693  0.2588   \n",
      "lr                    Logistic Regression    0.2660  0.0000  0.2660  0.2397   \n",
      "dt               Decision Tree Classifier    0.2660  0.5086  0.2660  0.2596   \n",
      "ridge                    Ridge Classifier    0.2660  0.0000  0.2660  0.2390   \n",
      "lda          Linear Discriminant Analysis    0.2565  0.0000  0.2565  0.2454   \n",
      "et                 Extra Trees Classifier    0.2561  0.5152  0.2561  0.2553   \n",
      "svm                   SVM - Linear Kernel    0.2435  0.0000  0.2435  0.2457   \n",
      "ada                  Ada Boost Classifier    0.2404  0.0000  0.2404  0.2389   \n",
      "knn                K Neighbors Classifier    0.2400  0.5081  0.2400  0.2510   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.2925  0.0565  0.0571     0.072  \n",
      "gbc       0.2897  0.0567  0.0575     0.205  \n",
      "qda       0.2790  0.0400  0.0405     0.009  \n",
      "nb        0.2710  0.0341  0.0355     0.010  \n",
      "catboost  0.2746  0.0344  0.0356     1.276  \n",
      "dummy     0.1189  0.0000  0.0000     0.009  \n",
      "lightgbm  0.2619  0.0317  0.0325     0.040  \n",
      "xgboost   0.2606  0.0202  0.0204     0.054  \n",
      "lr        0.2426  0.0094  0.0092     0.011  \n",
      "dt        0.2587  0.0166  0.0167     0.011  \n",
      "ridge     0.2425  0.0099  0.0092     0.010  \n",
      "lda       0.2404 -0.0013 -0.0022     0.013  \n",
      "et        0.2505 -0.0002 -0.0001     0.053  \n",
      "svm       0.1822 -0.0162 -0.0125     0.012  \n",
      "ada       0.2338 -0.0144 -0.0141     0.040  \n",
      "knn       0.2323 -0.0093 -0.0094     0.011  \n",
      "Best model: RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       monotonic_cst=None, n_estimators=100, n_jobs=1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "===== CLASSIFICATION – direction_binary – All sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape         (452, 19)\n",
      "5        Transformed data shape         (452, 19)\n",
      "6   Transformed train set shape         (316, 19)\n",
      "7    Transformed test set shape         (136, 19)\n",
      "8              Numeric features                18\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              b1a1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "lda          Linear Discriminant Analysis    0.5344  0.5591  0.5344  0.5290   \n",
      "dt               Decision Tree Classifier    0.5217  0.5153  0.5217  0.5222   \n",
      "svm                   SVM - Linear Kernel    0.5123  0.5227  0.5123  0.4772   \n",
      "gbc          Gradient Boosting Classifier    0.5034  0.4820  0.5034  0.4980   \n",
      "qda       Quadratic Discriminant Analysis    0.4992  0.5320  0.4992  0.5129   \n",
      "ada                  Ada Boost Classifier    0.4905  0.4721  0.4905  0.4895   \n",
      "ridge                    Ridge Classifier    0.4845  0.5004  0.4845  0.4691   \n",
      "xgboost         Extreme Gradient Boosting    0.4844  0.4585  0.4844  0.4775   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4843  0.4775  0.4843  0.4805   \n",
      "nb                            Naive Bayes    0.4778  0.5020  0.4778  0.5001   \n",
      "catboost              CatBoost Classifier    0.4777  0.4739  0.4777  0.4688   \n",
      "rf               Random Forest Classifier    0.4715  0.4435  0.4715  0.4643   \n",
      "lr                    Logistic Regression    0.4655  0.4770  0.4655  0.4498   \n",
      "et                 Extra Trees Classifier    0.4588  0.4768  0.4588  0.4539   \n",
      "knn                K Neighbors Classifier    0.4493  0.4424  0.4493  0.4455   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dummy     0.3802  0.0000  0.0000     0.009  \n",
      "lda       0.5256  0.0468  0.0488     0.010  \n",
      "dt        0.5165  0.0314  0.0342     0.011  \n",
      "svm       0.3944 -0.0175  0.0152     0.010  \n",
      "gbc       0.4904 -0.0163 -0.0138     0.090  \n",
      "qda       0.4910  0.0136  0.0158     0.010  \n",
      "ada       0.4845 -0.0294 -0.0290     0.046  \n",
      "ridge     0.4599 -0.0642 -0.0669     0.010  \n",
      "xgboost   0.4754 -0.0486 -0.0504     0.035  \n",
      "lightgbm  0.4787 -0.0450 -0.0456     0.021  \n",
      "nb        0.4310  0.0005 -0.0026     0.010  \n",
      "catboost  0.4630 -0.0693 -0.0696     1.273  \n",
      "rf        0.4613 -0.0780 -0.0786     0.073  \n",
      "lr        0.4323 -0.1082 -0.1095     0.011  \n",
      "et        0.4469 -0.1055 -0.1030     0.052  \n",
      "knn       0.4450 -0.1124 -0.1147     0.011  \n",
      "Best model: DummyClassifier(constant=None, random_state=42, strategy='prior')\n",
      "\n",
      "===== CLASSIFICATION – direction_binary – VADER sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape          (452, 8)\n",
      "5        Transformed data shape          (452, 8)\n",
      "6   Transformed train set shape          (316, 8)\n",
      "7    Transformed test set shape          (136, 8)\n",
      "8              Numeric features                 7\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              5f8f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lr                    Logistic Regression    0.5412  0.4809  0.5412  0.2930   \n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "ridge                    Ridge Classifier    0.5319  0.5023  0.5319  0.4823   \n",
      "lda          Linear Discriminant Analysis    0.5098  0.5308  0.5098  0.4978   \n",
      "qda       Quadratic Discriminant Analysis    0.5062  0.5291  0.5062  0.5436   \n",
      "svm                   SVM - Linear Kernel    0.5030  0.4994  0.5030  0.3314   \n",
      "ada                  Ada Boost Classifier    0.4808  0.4564  0.4808  0.4762   \n",
      "dt               Decision Tree Classifier    0.4781  0.4751  0.4781  0.4787   \n",
      "nb                            Naive Bayes    0.4779  0.5179  0.4779  0.5057   \n",
      "gbc          Gradient Boosting Classifier    0.4751  0.4539  0.4751  0.4699   \n",
      "rf               Random Forest Classifier    0.4622  0.4347  0.4622  0.4563   \n",
      "knn                K Neighbors Classifier    0.4531  0.4067  0.4531  0.4457   \n",
      "catboost              CatBoost Classifier    0.4497  0.4362  0.4497  0.4399   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4402  0.4299  0.4402  0.4380   \n",
      "xgboost         Extreme Gradient Boosting    0.4368  0.4415  0.4368  0.4336   \n",
      "et                 Extra Trees Classifier    0.4179  0.4278  0.4179  0.4111   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lr        0.3802  0.0000  0.0000     0.010  \n",
      "dummy     0.3802  0.0000  0.0000     0.008  \n",
      "ridge     0.3998 -0.0114  0.0022     0.009  \n",
      "lda       0.4922 -0.0070 -0.0092     0.009  \n",
      "qda       0.4604  0.0534  0.0655     0.008  \n",
      "svm       0.3589 -0.0137 -0.0128     0.009  \n",
      "ada       0.4763 -0.0547 -0.0550     0.039  \n",
      "dt        0.4771 -0.0498 -0.0499     0.010  \n",
      "nb        0.4284  0.0031  0.0029     0.008  \n",
      "gbc       0.4688 -0.0646 -0.0661     0.060  \n",
      "rf        0.4563 -0.0914 -0.0931     0.064  \n",
      "knn       0.4424 -0.1037 -0.1097     0.009  \n",
      "catboost  0.4395 -0.1218 -0.1247     0.795  \n",
      "lightgbm  0.4371 -0.1314 -0.1315     0.017  \n",
      "xgboost   0.4324 -0.1349 -0.1377     0.027  \n",
      "et        0.4124 -0.1811 -0.1836     0.048  \n",
      "Best model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "===== CLASSIFICATION – direction_binary – GenAI sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape          (452, 2)\n",
      "5        Transformed data shape          (452, 2)\n",
      "6   Transformed train set shape          (316, 2)\n",
      "7    Transformed test set shape          (136, 2)\n",
      "8              Numeric features                 1\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              2d23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.5636  0.5711  0.5636  0.5591   \n",
      "et                 Extra Trees Classifier    0.5538  0.5429  0.5538  0.5531   \n",
      "knn                K Neighbors Classifier    0.5508  0.5495  0.5508  0.5478   \n",
      "ridge                    Ridge Classifier    0.5413  0.5371  0.5413  0.3573   \n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "rf               Random Forest Classifier    0.5382  0.5677  0.5382  0.5334   \n",
      "lr                    Logistic Regression    0.5381  0.5371  0.5381  0.2922   \n",
      "dt               Decision Tree Classifier    0.5381  0.5482  0.5381  0.5369   \n",
      "lda          Linear Discriminant Analysis    0.5381  0.5371  0.5381  0.3565   \n",
      "xgboost         Extreme Gradient Boosting    0.5316  0.5453  0.5316  0.5305   \n",
      "svm                   SVM - Linear Kernel    0.5253  0.5114  0.5253  0.3044   \n",
      "ada                  Ada Boost Classifier    0.5220  0.5728  0.5220  0.5137   \n",
      "nb                            Naive Bayes    0.5125  0.5303  0.5125  0.4961   \n",
      "qda       Quadratic Discriminant Analysis    0.5125  0.5303  0.5125  0.4961   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5123  0.5493  0.5123  0.5054   \n",
      "catboost              CatBoost Classifier    0.4935  0.5521  0.4935  0.4829   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.5537  0.1103  0.1111     0.034  \n",
      "et        0.5497  0.0968  0.0982     0.044  \n",
      "knn       0.5429  0.0882  0.0888     0.009  \n",
      "ridge     0.3934  0.0033  0.0142     0.008  \n",
      "dummy     0.3802  0.0000  0.0000     0.008  \n",
      "rf        0.5315  0.0606  0.0604     0.057  \n",
      "lr        0.3787 -0.0062 -0.0169     0.009  \n",
      "dt        0.5336  0.0660  0.0666     0.008  \n",
      "lda       0.3918 -0.0031 -0.0024     0.008  \n",
      "xgboost   0.5254  0.0526  0.0535     0.016  \n",
      "svm       0.3675 -0.0012 -0.0026     0.008  \n",
      "ada       0.5096  0.0255  0.0231     0.035  \n",
      "nb        0.4880  0.0026 -0.0041     0.008  \n",
      "qda       0.4880  0.0026 -0.0041     0.008  \n",
      "lightgbm  0.4983  0.0016  0.0024     0.015  \n",
      "catboost  0.4790 -0.0376 -0.0395     0.232  \n",
      "Best model: GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=42, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "\n",
      "===== CLASSIFICATION – direction_binary – Sectoral sentiment =====\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape         (452, 11)\n",
      "5        Transformed data shape         (452, 11)\n",
      "6   Transformed train set shape         (316, 11)\n",
      "7    Transformed test set shape         (136, 11)\n",
      "8              Numeric features                10\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              4553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "xgboost         Extreme Gradient Boosting    0.5161  0.5059  0.5161  0.5148   \n",
      "rf               Random Forest Classifier    0.5157  0.4859  0.5157  0.5076   \n",
      "gbc          Gradient Boosting Classifier    0.5128  0.4870  0.5128  0.5146   \n",
      "ada                  Ada Boost Classifier    0.5041  0.4914  0.5041  0.5019   \n",
      "svm                   SVM - Linear Kernel    0.5004  0.4564  0.5004  0.4274   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4939  0.4945  0.4939  0.4924   \n",
      "catboost              CatBoost Classifier    0.4907  0.5101  0.4907  0.4831   \n",
      "lr                    Logistic Regression    0.4878  0.4568  0.4878  0.4943   \n",
      "ridge                    Ridge Classifier    0.4847  0.4571  0.4847  0.4752   \n",
      "lda          Linear Discriminant Analysis    0.4847  0.4538  0.4847  0.4755   \n",
      "et                 Extra Trees Classifier    0.4782  0.4826  0.4782  0.4659   \n",
      "qda       Quadratic Discriminant Analysis    0.4779  0.4659  0.4779  0.4771   \n",
      "nb                            Naive Bayes    0.4749  0.4560  0.4749  0.4697   \n",
      "dt               Decision Tree Classifier    0.4743  0.4730  0.4743  0.4768   \n",
      "knn                K Neighbors Classifier    0.4587  0.4495  0.4587  0.4558   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dummy     0.3802  0.0000  0.0000     0.008  \n",
      "xgboost   0.5113  0.0208  0.0217     0.024  \n",
      "rf        0.5043  0.0130  0.0107     0.065  \n",
      "gbc       0.5067  0.0139  0.0178     0.059  \n",
      "ada       0.4967 -0.0083 -0.0059     0.039  \n",
      "svm       0.4261 -0.0079 -0.0153     0.010  \n",
      "lightgbm  0.4894 -0.0227 -0.0226     0.018  \n",
      "catboost  0.4769 -0.0411 -0.0412     0.506  \n",
      "lr        0.4510 -0.0617 -0.0474     0.010  \n",
      "ridge     0.4500 -0.0670 -0.0639     0.010  \n",
      "lda       0.4508 -0.0672 -0.0639     0.009  \n",
      "et        0.4639 -0.0703 -0.0729     0.050  \n",
      "qda       0.4745 -0.0530 -0.0533     0.009  \n",
      "nb        0.4568 -0.0803 -0.0752     0.009  \n",
      "dt        0.4736 -0.0533 -0.0538     0.010  \n",
      "knn       0.4551 -0.0931 -0.0946     0.010  \n",
      "Best model: DummyClassifier(constant=None, random_state=42, strategy='prior')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>target</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>DirectionalAcc</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bucket_return</td>\n",
       "      <td>bucket_return</td>\n",
       "      <td>All sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.302564</td>\n",
       "      <td>0.247257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bucket_return</td>\n",
       "      <td>bucket_return</td>\n",
       "      <td>GenAI sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.353846</td>\n",
       "      <td>0.247107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bucket_return</td>\n",
       "      <td>bucket_return</td>\n",
       "      <td>Sectoral sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.218055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bucket_return</td>\n",
       "      <td>bucket_return</td>\n",
       "      <td>VADER sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.247018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>direction_binary</td>\n",
       "      <td>direction_binary</td>\n",
       "      <td>All sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.372990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>direction_binary</td>\n",
       "      <td>direction_binary</td>\n",
       "      <td>GenAI sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.489121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>direction_binary</td>\n",
       "      <td>direction_binary</td>\n",
       "      <td>Sectoral sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.372990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>direction_binary</td>\n",
       "      <td>direction_binary</td>\n",
       "      <td>VADER sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>0.372990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>regression</td>\n",
       "      <td>return_t_plus_1</td>\n",
       "      <td>All sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>1.377527</td>\n",
       "      <td>2.341142</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>regression</td>\n",
       "      <td>return_t_plus_1</td>\n",
       "      <td>GenAI sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>1.368240</td>\n",
       "      <td>2.341494</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>regression</td>\n",
       "      <td>return_t_plus_1</td>\n",
       "      <td>Sectoral sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>1.377527</td>\n",
       "      <td>2.341142</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>regression</td>\n",
       "      <td>return_t_plus_1</td>\n",
       "      <td>VADER sentiment</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>1.377527</td>\n",
       "      <td>2.341142</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                task            target         feature_set     model  \\\n",
       "0      bucket_return     bucket_return       All sentiment  Pipeline   \n",
       "1      bucket_return     bucket_return     GenAI sentiment  Pipeline   \n",
       "2      bucket_return     bucket_return  Sectoral sentiment  Pipeline   \n",
       "3      bucket_return     bucket_return     VADER sentiment  Pipeline   \n",
       "4   direction_binary  direction_binary       All sentiment  Pipeline   \n",
       "5   direction_binary  direction_binary     GenAI sentiment  Pipeline   \n",
       "6   direction_binary  direction_binary  Sectoral sentiment  Pipeline   \n",
       "7   direction_binary  direction_binary     VADER sentiment  Pipeline   \n",
       "8         regression   return_t_plus_1       All sentiment  Pipeline   \n",
       "9         regression   return_t_plus_1     GenAI sentiment  Pipeline   \n",
       "10        regression   return_t_plus_1  Sectoral sentiment  Pipeline   \n",
       "11        regression   return_t_plus_1     VADER sentiment  Pipeline   \n",
       "\n",
       "         MAE      RMSE        R2  DirectionalAcc  Accuracy  F1_macro  \n",
       "0        NaN       NaN       NaN             NaN  0.302564  0.247257  \n",
       "1        NaN       NaN       NaN             NaN  0.353846  0.247107  \n",
       "2        NaN       NaN       NaN             NaN  0.230769  0.218055  \n",
       "3        NaN       NaN       NaN             NaN  0.400000  0.247018  \n",
       "4        NaN       NaN       NaN             NaN  0.594872  0.372990  \n",
       "5        NaN       NaN       NaN             NaN  0.512821  0.489121  \n",
       "6        NaN       NaN       NaN             NaN  0.594872  0.372990  \n",
       "7        NaN       NaN       NaN             NaN  0.594872  0.372990  \n",
       "8   1.377527  2.341142 -0.000768        0.594872       NaN       NaN  \n",
       "9   1.368240  2.341494 -0.001069        0.600000       NaN       NaN  \n",
       "10  1.377527  2.341142 -0.000768        0.594872       NaN       NaN  \n",
       "11  1.377527  2.341142 -0.000768        0.594872       NaN       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "from pycaret.regression import (\n",
    "    setup as reg_setup,\n",
    "    compare_models as reg_compare,\n",
    "    finalize_model as reg_finalize,\n",
    "    predict_model as reg_predict,\n",
    ")\n",
    "\n",
    "from pycaret.classification import (\n",
    "    setup as clf_setup,\n",
    "    compare_models as clf_compare,\n",
    "    finalize_model as clf_finalize,\n",
    "    predict_model as clf_predict,\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 0. DEFINE FEATURE SETS (plug in your actual lists here)\n",
    "# -------------------------------------------------------------------\n",
    "feature_sets = {\n",
    "    \"All sentiment\":      feature_cols_all,     # e.g. all sentiment features\n",
    "    \"VADER sentiment\":    feature_cols_vader,\n",
    "    \"GenAI sentiment\":    feature_cols_genai,\n",
    "    \"Sectoral sentiment\": feature_cols_sector,  # category-based indices\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1. HELPER: DETECT PREDICTION COLUMN FROM predict_model()\n",
    "# -------------------------------------------------------------------\n",
    "def get_prediction_column(pred_df: pd.DataFrame, feature_cols):\n",
    "    \"\"\"\n",
    "    pred_df: DataFrame returned by pycaret.predict_model\n",
    "    feature_cols: list of feature column names used in X_test\n",
    "\n",
    "    Returns the name of the column that contains predictions\n",
    "    (works even if it's not called 'Label').\n",
    "    \"\"\"\n",
    "    extra_cols = [c for c in pred_df.columns if c not in feature_cols]\n",
    "    # You can print once to inspect:\n",
    "    # print(\"Extra prediction columns:\", extra_cols)\n",
    "    pred_col = extra_cols[0]\n",
    "    return pred_col\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. GLOBAL RESULTS LIST + LOGGING HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "results = []\n",
    "\n",
    "def log_regression_result(target, feature_set, model, y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "\n",
    "    # directional accuracy: sign of return (up vs non-up)\n",
    "    true_dir = np.where(y_true > 0, 1, 0)\n",
    "    pred_dir = np.where(y_pred > 0, 1, 0)\n",
    "    dir_acc  = (true_dir == pred_dir).mean()\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"task\":          \"regression\",\n",
    "            \"target\":        target,\n",
    "            \"feature_set\":   feature_set,\n",
    "            \"model\":         model.__class__.__name__,\n",
    "            \"MAE\":           mae,\n",
    "            \"RMSE\":          rmse,\n",
    "            \"R2\":            r2,\n",
    "            \"DirectionalAcc\": dir_acc,\n",
    "            \"Accuracy\":      np.nan,\n",
    "            \"F1_macro\":      np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "def log_classification_result(task_name, feature_set, model, y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1  = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"task\":          task_name,              # 'bucket_return' or 'direction_binary'\n",
    "            \"target\":        task_name,\n",
    "            \"feature_set\":   feature_set,\n",
    "            \"model\":         model.__class__.__name__,\n",
    "            \"MAE\":           np.nan,\n",
    "            \"RMSE\":          np.nan,\n",
    "            \"R2\":            np.nan,\n",
    "            \"DirectionalAcc\": np.nan,\n",
    "            \"Accuracy\":      acc,\n",
    "            \"F1_macro\":      f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# ===================================================================\n",
    "# 3. REGRESSION: return_t_plus_1  (4 feature sets)\n",
    "# ===================================================================\n",
    "for fs_name, fs_cols in feature_sets.items():\n",
    "    print(f\"\\n===== REGRESSION – return_t_plus_1 – {fs_name} =====\\n\")\n",
    "\n",
    "    reg_train = train_df[fs_cols + [\"return_t_plus_1\"]].copy()\n",
    "\n",
    "    reg_setup(\n",
    "        data=reg_train,\n",
    "        target=\"return_t_plus_1\",\n",
    "        session_id=42,\n",
    "        html=False,\n",
    "        log_experiment=False,\n",
    "        n_jobs=1,      # avoid joblib issues on Mac\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    best_reg = reg_compare(sort=\"MAE\", turbo=True)\n",
    "    print(\"Best model:\", best_reg)\n",
    "\n",
    "    final_reg = reg_finalize(best_reg)\n",
    "\n",
    "    X_test = test_df[fs_cols].copy()\n",
    "    y_test = test_df[\"return_t_plus_1\"].copy()\n",
    "\n",
    "    pred_df = reg_predict(final_reg, data=X_test)\n",
    "    pred_col = get_prediction_column(pred_df, fs_cols)\n",
    "    y_pred = pred_df[pred_col]\n",
    "\n",
    "    log_regression_result(\n",
    "        target=\"return_t_plus_1\",\n",
    "        feature_set=fs_name,\n",
    "        model=final_reg,\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "\n",
    "# ===================================================================\n",
    "# 4. CLASSIFICATION: bucket_return  (multi-class, 4 feature sets)\n",
    "# ===================================================================\n",
    "for fs_name, fs_cols in feature_sets.items():\n",
    "    print(f\"\\n===== CLASSIFICATION – return_bucket – {fs_name} =====\\n\")\n",
    "\n",
    "    cls_train = train_df[fs_cols + [\"return_bucket\"]].copy()\n",
    "\n",
    "    clf_setup(\n",
    "        data=cls_train,\n",
    "        target=\"return_bucket\",\n",
    "        session_id=42,\n",
    "        html=False,\n",
    "        log_experiment=False,\n",
    "        n_jobs=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    best_cls = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "    print(\"Best model:\", best_cls)\n",
    "\n",
    "    final_cls = clf_finalize(best_cls)\n",
    "\n",
    "    X_test = test_df[fs_cols].copy()\n",
    "    y_test = test_df[\"return_bucket\"].copy()\n",
    "\n",
    "    pred_df = clf_predict(final_cls, data=X_test)\n",
    "    pred_col = get_prediction_column(pred_df, fs_cols)\n",
    "    y_pred = pred_df[pred_col]\n",
    "\n",
    "    log_classification_result(\n",
    "        task_name=\"bucket_return\",\n",
    "        feature_set=fs_name,\n",
    "        model=final_cls,\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "\n",
    "# ===================================================================\n",
    "# 5. CLASSIFICATION: direction_binary (binary, 4 feature sets)\n",
    "# ===================================================================\n",
    "for fs_name, fs_cols in feature_sets.items():\n",
    "    print(f\"\\n===== CLASSIFICATION – direction_binary – {fs_name} =====\\n\")\n",
    "\n",
    "    bin_train = train_df[fs_cols + [\"direction_binary\"]].copy()\n",
    "\n",
    "    clf_setup(\n",
    "        data=bin_train,\n",
    "        target=\"direction_binary\",\n",
    "        session_id=42,\n",
    "        html=False,\n",
    "        log_experiment=False,\n",
    "        n_jobs=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    best_bin = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "    print(\"Best model:\", best_bin)\n",
    "\n",
    "    final_bin = clf_finalize(best_bin)\n",
    "\n",
    "    X_test = test_df[fs_cols].copy()\n",
    "    y_test = test_df[\"direction_binary\"].copy()\n",
    "\n",
    "    pred_df = clf_predict(final_bin, data=X_test)\n",
    "    pred_col = get_prediction_column(pred_df, fs_cols)\n",
    "    y_pred = pred_df[pred_col]\n",
    "\n",
    "    log_classification_result(\n",
    "        task_name=\"direction_binary\",\n",
    "        feature_set=fs_name,\n",
    "        model=final_bin,\n",
    "        y_true=y_test,\n",
    "        y_pred=y_pred,\n",
    "    )\n",
    "\n",
    "# ===================================================================\n",
    "# 6. SUMMARY EVALUATION TABLE\n",
    "# ===================================================================\n",
    "summary_df = pd.DataFrame(results).sort_values(\n",
    "    by=[\"task\", \"feature_set\"]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "display(summary_df)\n",
    "\n",
    "# Optionally save\n",
    "summary_df.to_csv(\"model_summary_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: Auto ML by hand (just for look at the detail result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model (Target = return_t_plus_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = All sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentiment = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "    \"sentiment_score\",\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ REGRESSION: return_t_plus_1 ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape         (452, 19)\n",
      "4        Transformed data shape         (452, 19)\n",
      "5   Transformed train set shape         (316, 19)\n",
      "6    Transformed test set shape         (136, 19)\n",
      "7              Numeric features                18\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              049d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model          MAE           MSE  \\\n",
      "lasso                    Lasso Regression       0.7166  1.037300e+00   \n",
      "llar         Lasso Least Angle Regression       0.7166  1.037300e+00   \n",
      "dummy                     Dummy Regressor       0.7166  1.037300e+00   \n",
      "en                            Elastic Net       0.7166  1.037300e+00   \n",
      "br                         Bayesian Ridge       0.7174  1.038600e+00   \n",
      "omp           Orthogonal Matching Pursuit       0.7328  1.071900e+00   \n",
      "huber                     Huber Regressor       0.7501  1.087100e+00   \n",
      "ridge                    Ridge Regression       0.7603  1.095700e+00   \n",
      "et                  Extra Trees Regressor       0.7689  1.135800e+00   \n",
      "rf                Random Forest Regressor       0.7701  1.153700e+00   \n",
      "lr                      Linear Regression       0.7720  1.104500e+00   \n",
      "catboost               CatBoost Regressor       0.7961  1.208900e+00   \n",
      "knn                 K Neighbors Regressor       0.8075  1.201700e+00   \n",
      "ada                    AdaBoost Regressor       0.8204  1.271000e+00   \n",
      "lightgbm  Light Gradient Boosting Machine       0.8376  1.266800e+00   \n",
      "gbr           Gradient Boosting Regressor       0.8416  1.287000e+00   \n",
      "xgboost         Extreme Gradient Boosting       0.8527  1.350500e+00   \n",
      "dt                Decision Tree Regressor       1.0498  2.033500e+00   \n",
      "par          Passive Aggressive Regressor       1.1834  2.155700e+00   \n",
      "lar                Least Angle Regression  288904.2132  1.497891e+12   \n",
      "\n",
      "                 RMSE            R2   RMSLE          MAPE  TT (Sec)  \n",
      "lasso          1.0001 -4.830000e-02  0.5662  1.243900e+00     0.005  \n",
      "llar           1.0001 -4.830000e-02  0.5662  1.243900e+00     0.005  \n",
      "dummy          1.0001 -4.830000e-02  0.5662  1.243900e+00     0.004  \n",
      "en             1.0001 -4.830000e-02  0.5662  1.243900e+00     0.005  \n",
      "br             1.0007 -4.940000e-02  0.5663  1.252700e+00     0.006  \n",
      "omp            1.0173 -8.560000e-02  0.5337  1.615200e+00     0.006  \n",
      "huber          1.0280 -1.187000e-01  0.4666  3.047500e+00     0.011  \n",
      "ridge          1.0301 -1.181000e-01  0.4993  1.962000e+00     0.005  \n",
      "et             1.0460 -1.529000e-01  0.4659  2.522200e+00     0.077  \n",
      "rf             1.0551 -1.702000e-01  0.4702  3.187100e+00     0.150  \n",
      "lr             1.0352 -1.368000e-01  0.4627  3.209800e+00     0.006  \n",
      "catboost       1.0813 -2.347000e-01  0.4472  3.475900e+00     1.191  \n",
      "knn            1.0766 -2.222000e-01  0.4369  4.866300e+00     0.007  \n",
      "ada            1.1050 -2.852000e-01  0.4283  3.290100e+00     0.042  \n",
      "lightgbm       1.1040 -2.990000e-01  0.4243  6.597200e+00     0.015  \n",
      "gbr            1.1196 -3.371000e-01  0.4307  3.391900e+00     0.071  \n",
      "xgboost        1.1396 -3.772000e-01  0.4319  9.320000e+00     0.057  \n",
      "dt             1.4143 -1.217200e+00  0.4887  5.674900e+00     0.007  \n",
      "par            1.4356 -1.249800e+00  0.4600  7.304100e+00     0.005  \n",
      "lar       387035.7993 -2.150486e+12  2.3026  5.944766e+06     0.010  \n",
      "Best model (Regression): Lasso(random_state=42)\n",
      "\n",
      "Regression – return_t_plus_1 results:\n",
      "Prediction column: prediction_label\n",
      "MAE : 1.3775265213315886\n",
      "RMSE: 2.3411424399896505\n",
      "R²  : -0.0007683865548917534\n",
      "Directional Accuracy (up vs down): 0.5948717948717949\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import (\n",
    "    setup as reg_setup,\n",
    "    compare_models as reg_compare,\n",
    "    finalize_model as reg_finalize,\n",
    "    predict_model as reg_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ REGRESSION: return_t_plus_1 ================\\n\")\n",
    "\n",
    "reg_train = train_df[all_sentiment + [\"return_t_plus_1\"]].copy()\n",
    "\n",
    "reg_setup(\n",
    "    data=reg_train,\n",
    "    target=\"return_t_plus_1\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,    # avoid joblib multiprocessing issues on Mac\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 🚀 AutoML over FULL model library (no include=...)\n",
    "best_reg_all = reg_compare(sort=\"MAE\", turbo=True)\n",
    "print(\"Best model (Regression):\", best_reg_all)\n",
    "\n",
    "# ❌ No tune_model (some models have no param grid) → just finalize\n",
    "final_reg_all = reg_finalize(best_reg_all)\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test_reg_all = test_df[all_sentiment].copy()\n",
    "y_test_reg_all = test_df[\"return_t_plus_1\"].copy()\n",
    "\n",
    "pred_reg = reg_predict(final_reg_all , data=X_test_reg)\n",
    "pred_col_reg = get_prediction_column(pred_reg, all_sentiment)\n",
    "y_pred_reg_all = pred_reg[pred_col_reg]\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "r2   = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "# 🔹 Directional accuracy (up/down based on 0 threshold)\n",
    "true_dir = np.where(y_test_reg > 0, 1, 0)   # 1 = up, 0 = down/flat\n",
    "pred_dir = np.where(y_pred_reg > 0, 1, 0)\n",
    "\n",
    "directional_acc = (true_dir == pred_dir).mean()\n",
    "\n",
    "print(\"\\nRegression – return_t_plus_1 results:\")\n",
    "print(\"Prediction column:\", pred_col_reg)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²  :\", r2)\n",
    "print(\"Directional Accuracy (up vs down):\", directional_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = Only the VADER sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ REGRESSION: return_t_plus_1 ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape          (452, 8)\n",
      "4        Transformed data shape          (452, 8)\n",
      "5   Transformed train set shape          (316, 8)\n",
      "6    Transformed test set shape          (136, 8)\n",
      "7              Numeric features                 7\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              d73e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE       MSE    RMSE        R2  \\\n",
      "lasso                    Lasso Regression  0.7166    1.0373  1.0001   -0.0483   \n",
      "llar         Lasso Least Angle Regression  0.7166    1.0373  1.0001   -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166    1.0373  1.0001   -0.0483   \n",
      "en                            Elastic Net  0.7166    1.0373  1.0001   -0.0483   \n",
      "ridge                    Ridge Regression  0.7184    1.0391  1.0011   -0.0506   \n",
      "huber                     Huber Regressor  0.7202    1.0314  0.9995   -0.0535   \n",
      "br                         Bayesian Ridge  0.7219    1.0511  1.0069   -0.0630   \n",
      "omp           Orthogonal Matching Pursuit  0.7273    1.0540  1.0080   -0.0647   \n",
      "lr                      Linear Regression  0.7328    1.0419  1.0044   -0.0652   \n",
      "rf                Random Forest Regressor  0.7670    1.1206  1.0399   -0.1347   \n",
      "et                  Extra Trees Regressor  0.7685    1.1241  1.0390   -0.1301   \n",
      "catboost               CatBoost Regressor  0.8030    1.2032  1.0775   -0.2219   \n",
      "ada                    AdaBoost Regressor  0.8103    1.2431  1.0946   -0.2624   \n",
      "gbr           Gradient Boosting Regressor  0.8104    1.2318  1.0881   -0.2413   \n",
      "lightgbm  Light Gradient Boosting Machine  0.8121    1.1888  1.0688   -0.2067   \n",
      "knn                 K Neighbors Regressor  0.8209    1.2350  1.0931   -0.2651   \n",
      "xgboost         Extreme Gradient Boosting  0.8728    1.3660  1.1461   -0.4032   \n",
      "dt                Decision Tree Regressor  1.1265    2.3416  1.5025   -1.4353   \n",
      "par          Passive Aggressive Regressor  1.5540    3.1349  1.7389   -2.4726   \n",
      "lar                Least Angle Regression  6.0936  167.5897  7.6535 -233.7604   \n",
      "\n",
      "           RMSLE     MAPE  TT (Sec)  \n",
      "lasso     0.5662   1.2439     0.004  \n",
      "llar      0.5662   1.2439     0.004  \n",
      "dummy     0.5662   1.2439     0.004  \n",
      "en        0.5662   1.2439     0.004  \n",
      "ridge     0.5479   1.3684     0.004  \n",
      "huber     0.4833   3.0933     0.009  \n",
      "br        0.5527   1.2930     0.004  \n",
      "omp       0.5471   1.2963     0.004  \n",
      "lr        0.4698   3.1104     0.004  \n",
      "rf        0.4626   3.3747     0.093  \n",
      "et        0.4597   3.7017     0.048  \n",
      "catboost  0.4473   5.1121     0.712  \n",
      "ada       0.4350   3.0448     0.029  \n",
      "gbr       0.4551   4.9332     0.041  \n",
      "lightgbm  0.4299   4.9094     0.012  \n",
      "knn       0.4343   6.4090     0.004  \n",
      "xgboost   0.4432  11.2855     0.041  \n",
      "dt        0.4819  13.6424     0.005  \n",
      "par       0.5244  19.8148     0.004  \n",
      "lar       1.0555  43.1127     0.004  \n",
      "Best model (Regression): Lasso(random_state=42)\n",
      "\n",
      "Regression – return_t_plus_1 results:\n",
      "Prediction column: prediction_label\n",
      "MAE : 1.3775265213315886\n",
      "RMSE: 2.3411424399896505\n",
      "R²  : -0.0007683865548917534\n",
      "Directional Accuracy (up vs down): 0.5948717948717949\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import (\n",
    "    setup as reg_setup,\n",
    "    compare_models as reg_compare,\n",
    "    finalize_model as reg_finalize,\n",
    "    predict_model as reg_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ REGRESSION: return_t_plus_1 ================\\n\")\n",
    "\n",
    "reg_train = train_df[feature_cols + [\"return_t_plus_1\"]].copy()\n",
    "\n",
    "reg_setup(\n",
    "    data=reg_train,\n",
    "    target=\"return_t_plus_1\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,    # avoid joblib multiprocessing issues on Mac\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 🚀 AutoML over FULL model library (no include=...)\n",
    "best_reg = reg_compare(sort=\"MAE\", turbo=True)\n",
    "print(\"Best model (Regression):\", best_reg)\n",
    "\n",
    "# ❌ No tune_model (some models have no param grid) → just finalize\n",
    "final_reg = reg_finalize(best_reg)\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test_reg = test_df[feature_cols].copy()\n",
    "y_test_reg = test_df[\"return_t_plus_1\"].copy()\n",
    "\n",
    "pred_reg = reg_predict(final_reg, data=X_test_reg)\n",
    "pred_col_reg = get_prediction_column(pred_reg, feature_cols)\n",
    "y_pred_reg = pred_reg[pred_col_reg]\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "r2   = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "# 🔹 Directional accuracy (up/down based on 0 threshold)\n",
    "true_dir = np.where(y_test_reg > 0, 1, 0)   # 1 = up, 0 = down/flat\n",
    "pred_dir = np.where(y_pred_reg > 0, 1, 0)\n",
    "\n",
    "directional_acc = (true_dir == pred_dir).mean()\n",
    "\n",
    "print(\"\\nRegression – return_t_plus_1 results:\")\n",
    "print(\"Prediction column:\", pred_col_reg)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²  :\", r2)\n",
    "print(\"Directional Accuracy (up vs down):\", directional_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = only the GenAI sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_score\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ REGRESSION: return_t_plus_1 ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape          (452, 2)\n",
      "4        Transformed data shape          (452, 2)\n",
      "5   Transformed train set shape          (316, 2)\n",
      "6    Transformed test set shape          (136, 2)\n",
      "7              Numeric features                 1\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              c6b4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE     MSE    RMSE      R2  \\\n",
      "huber                     Huber Regressor  0.7159  1.0444  1.0060 -0.0660   \n",
      "llar         Lasso Least Angle Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166  1.0373  1.0001 -0.0483   \n",
      "lasso                    Lasso Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "en                            Elastic Net  0.7166  1.0373  1.0001 -0.0483   \n",
      "br                         Bayesian Ridge  0.7190  1.0475  1.0057 -0.0611   \n",
      "ridge                    Ridge Regression  0.7192  1.0444  1.0048 -0.0605   \n",
      "omp           Orthogonal Matching Pursuit  0.7203  1.0461  1.0059 -0.0633   \n",
      "lr                      Linear Regression  0.7203  1.0461  1.0059 -0.0633   \n",
      "lar                Least Angle Regression  0.7203  1.0461  1.0059 -0.0633   \n",
      "lightgbm  Light Gradient Boosting Machine  0.7583  1.1292  1.0482 -0.1617   \n",
      "gbr           Gradient Boosting Regressor  0.8046  1.3016  1.1184 -0.3168   \n",
      "ada                    AdaBoost Regressor  0.8072  1.1662  1.0626 -0.1916   \n",
      "catboost               CatBoost Regressor  0.8104  1.3189  1.1221 -0.3160   \n",
      "knn                 K Neighbors Regressor  0.8170  1.2846  1.1162 -0.3193   \n",
      "rf                Random Forest Regressor  0.8905  1.5242  1.2137 -0.5605   \n",
      "et                  Extra Trees Regressor  0.9617  1.6704  1.2790 -0.7681   \n",
      "xgboost         Extreme Gradient Boosting  1.0002  1.8205  1.3432 -1.0355   \n",
      "dt                Decision Tree Regressor  1.0387  1.9661  1.3792 -1.0314   \n",
      "par          Passive Aggressive Regressor  1.1311  2.0791  1.3765 -1.1128   \n",
      "\n",
      "           RMSLE    MAPE  TT (Sec)  \n",
      "huber     0.5156  1.6747     0.005  \n",
      "llar      0.5662  1.2439     0.004  \n",
      "dummy     0.5662  1.2439     0.003  \n",
      "lasso     0.5662  1.2439     0.004  \n",
      "en        0.5662  1.2439     0.004  \n",
      "br        0.5552  1.1076     0.004  \n",
      "ridge     0.5462  1.2884     0.004  \n",
      "omp       0.5423  1.3696     0.004  \n",
      "lr        0.5423  1.3696     0.004  \n",
      "lar       0.5423  1.3696     0.004  \n",
      "lightgbm  0.4558  2.5856     0.009  \n",
      "gbr       0.4790  2.6152     0.019  \n",
      "ada       0.4643  3.3545     0.010  \n",
      "catboost  0.4680  3.1945     0.140  \n",
      "knn       0.4286  5.3585     0.004  \n",
      "rf        0.4438  4.1866     0.045  \n",
      "et        0.4575  5.0066     0.032  \n",
      "xgboost   0.4878  9.1152     0.013  \n",
      "dt        0.4843  8.7181     0.004  \n",
      "par       0.4494  8.0333     0.004  \n",
      "Best model (Regression): HuberRegressor()\n",
      "\n",
      "Regression – return_t_plus_1 results:\n",
      "Prediction column: prediction_label\n",
      "MAE : 1.368239656075412\n",
      "RMSE: 2.3414938273669534\n",
      "R²  : -0.0010688242926033542\n",
      "Directional Accuracy (up vs down): 0.6\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import (\n",
    "    setup as reg_setup,\n",
    "    compare_models as reg_compare,\n",
    "    finalize_model as reg_finalize,\n",
    "    predict_model as reg_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ REGRESSION: return_t_plus_1 ================\\n\")\n",
    "\n",
    "reg_train = train_df[feature_cols + [\"return_t_plus_1\"]].copy()\n",
    "\n",
    "reg_setup(\n",
    "    data=reg_train,\n",
    "    target=\"return_t_plus_1\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,    # avoid joblib multiprocessing issues on Mac\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 🚀 AutoML over FULL model library (no include=...)\n",
    "best_reg = reg_compare(sort=\"MAE\", turbo=True)\n",
    "print(\"Best model (Regression):\", best_reg)\n",
    "\n",
    "# ❌ No tune_model (some models have no param grid) → just finalize\n",
    "final_reg = reg_finalize(best_reg)\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test_reg = test_df[feature_cols].copy()\n",
    "y_test_reg = test_df[\"return_t_plus_1\"].copy()\n",
    "\n",
    "pred_reg = reg_predict(final_reg, data=X_test_reg)\n",
    "pred_col_reg = get_prediction_column(pred_reg, feature_cols)\n",
    "y_pred_reg = pred_reg[pred_col_reg]\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "r2   = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "# 🔹 Directional accuracy (up/down based on 0 threshold)\n",
    "true_dir = np.where(y_test_reg > 0, 1, 0)   # 1 = up, 0 = down/flat\n",
    "pred_dir = np.where(y_pred_reg > 0, 1, 0)\n",
    "\n",
    "directional_acc = (true_dir == pred_dir).mean()\n",
    "\n",
    "print(\"\\nRegression – return_t_plus_1 results:\")\n",
    "print(\"Prediction column:\", pred_col_reg)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²  :\", r2)\n",
    "print(\"Directional Accuracy (up vs down):\", directional_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = Sectoral sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ REGRESSION: return_t_plus_1 ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target   return_t_plus_1\n",
      "2                   Target type        Regression\n",
      "3           Original data shape         (452, 11)\n",
      "4        Transformed data shape         (452, 11)\n",
      "5   Transformed train set shape         (316, 11)\n",
      "6    Transformed test set shape         (136, 11)\n",
      "7              Numeric features                10\n",
      "8                    Preprocess              True\n",
      "9               Imputation type            simple\n",
      "10           Numeric imputation              mean\n",
      "11       Categorical imputation              mode\n",
      "12               Fold Generator             KFold\n",
      "13                  Fold Number                10\n",
      "14                     CPU Jobs                 1\n",
      "15                      Use GPU             False\n",
      "16               Log Experiment             False\n",
      "17              Experiment Name  reg-default-name\n",
      "18                          USI              8fcb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model     MAE     MSE    RMSE      R2  \\\n",
      "lasso                    Lasso Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "llar         Lasso Least Angle Regression  0.7166  1.0373  1.0001 -0.0483   \n",
      "dummy                     Dummy Regressor  0.7166  1.0373  1.0001 -0.0483   \n",
      "en                            Elastic Net  0.7166  1.0373  1.0001 -0.0483   \n",
      "br                         Bayesian Ridge  0.7174  1.0387  1.0007 -0.0495   \n",
      "omp           Orthogonal Matching Pursuit  0.7328  1.0719  1.0173 -0.0856   \n",
      "huber                     Huber Regressor  0.7346  1.0726  1.0194 -0.0948   \n",
      "ridge                    Ridge Regression  0.7563  1.0903  1.0270 -0.1096   \n",
      "lr                      Linear Regression  0.7585  1.0928  1.0283 -0.1127   \n",
      "lar                Least Angle Regression  0.7585  1.0928  1.0283 -0.1127   \n",
      "rf                Random Forest Regressor  0.7841  1.1709  1.0668 -0.2075   \n",
      "et                  Extra Trees Regressor  0.7967  1.1898  1.0743 -0.2245   \n",
      "knn                 K Neighbors Regressor  0.8033  1.1952  1.0758 -0.2230   \n",
      "catboost               CatBoost Regressor  0.8319  1.2744  1.1121 -0.3175   \n",
      "ada                    AdaBoost Regressor  0.8357  1.2265  1.0895 -0.2530   \n",
      "lightgbm  Light Gradient Boosting Machine  0.8500  1.2878  1.1163 -0.3222   \n",
      "gbr           Gradient Boosting Regressor  0.8622  1.3155  1.1337 -0.3746   \n",
      "xgboost         Extreme Gradient Boosting  0.9147  1.4833  1.2037 -0.5583   \n",
      "dt                Decision Tree Regressor  1.1308  2.2960  1.4975 -1.4374   \n",
      "par          Passive Aggressive Regressor  1.1606  2.2217  1.4654 -1.3043   \n",
      "\n",
      "           RMSLE     MAPE  TT (Sec)  \n",
      "lasso     0.5662   1.2439     0.005  \n",
      "llar      0.5662   1.2439     0.005  \n",
      "dummy     0.5662   1.2439     0.004  \n",
      "en        0.5662   1.2439     0.005  \n",
      "br        0.5663   1.2568     0.005  \n",
      "omp       0.5337   1.6152     0.005  \n",
      "huber     0.5128   1.7057     0.006  \n",
      "ridge     0.5107   1.8922     0.005  \n",
      "lr        0.5083   1.9238     0.005  \n",
      "lar       0.5083   1.9238     0.005  \n",
      "rf        0.4720   2.3788     0.092  \n",
      "et        0.4748   2.4905     0.058  \n",
      "knn       0.4432   4.8580     0.005  \n",
      "catboost  0.4429   3.0434     0.418  \n",
      "ada       0.4572   3.0085     0.030  \n",
      "lightgbm  0.4491   3.6969     0.014  \n",
      "gbr       0.4602   3.8070     0.043  \n",
      "xgboost   0.4455   3.8660     0.037  \n",
      "dt        0.4874  14.6212     0.006  \n",
      "par       0.4648   6.9747     0.005  \n",
      "Best model (Regression): Lasso(random_state=42)\n",
      "\n",
      "Regression – return_t_plus_1 results:\n",
      "Prediction column: prediction_label\n",
      "MAE : 1.3775265213315886\n",
      "RMSE: 2.3411424399896505\n",
      "R²  : -0.0007683865548917534\n",
      "Directional Accuracy (up vs down): 0.5948717948717949\n"
     ]
    }
   ],
   "source": [
    "from pycaret.regression import (\n",
    "    setup as reg_setup,\n",
    "    compare_models as reg_compare,\n",
    "    finalize_model as reg_finalize,\n",
    "    predict_model as reg_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ REGRESSION: return_t_plus_1 ================\\n\")\n",
    "\n",
    "reg_train = train_df[feature_cols + [\"return_t_plus_1\"]].copy()\n",
    "\n",
    "reg_setup(\n",
    "    data=reg_train,\n",
    "    target=\"return_t_plus_1\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,    # avoid joblib multiprocessing issues on Mac\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 🚀 AutoML over FULL model library (no include=...)\n",
    "best_reg = reg_compare(sort=\"MAE\", turbo=True)\n",
    "print(\"Best model (Regression):\", best_reg)\n",
    "\n",
    "# ❌ No tune_model (some models have no param grid) → just finalize\n",
    "final_reg = reg_finalize(best_reg)\n",
    "\n",
    "# Evaluate on test set\n",
    "X_test_reg = test_df[feature_cols].copy()\n",
    "y_test_reg = test_df[\"return_t_plus_1\"].copy()\n",
    "\n",
    "pred_reg = reg_predict(final_reg, data=X_test_reg)\n",
    "pred_col_reg = get_prediction_column(pred_reg, feature_cols)\n",
    "y_pred_reg = pred_reg[pred_col_reg]\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
    "r2   = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "# 🔹 Directional accuracy (up/down based on 0 threshold)\n",
    "true_dir = np.where(y_test_reg > 0, 1, 0)   # 1 = up, 0 = down/flat\n",
    "pred_dir = np.where(y_pred_reg > 0, 1, 0)\n",
    "\n",
    "directional_acc = (true_dir == pred_dir).mean()\n",
    "\n",
    "print(\"\\nRegression – return_t_plus_1 results:\")\n",
    "print(\"Prediction column:\", pred_col_reg)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R²  :\", r2)\n",
    "print(\"Directional Accuracy (up vs down):\", directional_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model_1 (Target = return_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature = All Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "    \"sentiment_score\",\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION: return_bucket ================\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                          (452, 19)  \n",
      "5                                          (452, 19)  \n",
      "6                                          (316, 19)  \n",
      "7                                          (136, 19)  \n",
      "8                                                 18  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              3fc0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "nb                            Naive Bayes    0.3075  0.5898  0.3075  0.3135   \n",
      "et                 Extra Trees Classifier    0.2979  0.5552  0.2979  0.2863   \n",
      "lda          Linear Discriminant Analysis    0.2880  0.0000  0.2880  0.2761   \n",
      "xgboost         Extreme Gradient Boosting    0.2787  0.5074  0.2787  0.2816   \n",
      "catboost              CatBoost Classifier    0.2787  0.5148  0.2787  0.2813   \n",
      "gbc          Gradient Boosting Classifier    0.2784  0.0000  0.2784  0.2808   \n",
      "rf               Random Forest Classifier    0.2783  0.5373  0.2783  0.2751   \n",
      "svm                   SVM - Linear Kernel    0.2755  0.0000  0.2755  0.1773   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2752  0.5111  0.2752  0.2824   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "ridge                    Ridge Classifier    0.2689  0.0000  0.2689  0.2398   \n",
      "lr                    Logistic Regression    0.2659  0.0000  0.2659  0.2429   \n",
      "ada                  Ada Boost Classifier    0.2625  0.0000  0.2625  0.2726   \n",
      "qda       Quadratic Discriminant Analysis    0.2560  0.0000  0.2560  0.2698   \n",
      "knn                K Neighbors Classifier    0.2212  0.5171  0.2212  0.2252   \n",
      "dt               Decision Tree Classifier    0.1999  0.4670  0.1999  0.2053   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "nb        0.2832  0.0776  0.0822     0.009  \n",
      "et        0.2781  0.0549  0.0586     0.055  \n",
      "lda       0.2759  0.0461  0.0469     0.009  \n",
      "xgboost   0.2695  0.0323  0.0333     0.090  \n",
      "catboost  0.2697  0.0307  0.0313     3.901  \n",
      "gbc       0.2666  0.0303  0.0317     0.322  \n",
      "rf        0.2640  0.0279  0.0287     0.079  \n",
      "svm       0.1794  0.0217  0.0269     0.011  \n",
      "lightgbm  0.2683  0.0274  0.0293     0.050  \n",
      "dummy     0.1189  0.0000  0.0000     0.010  \n",
      "ridge     0.2442  0.0139  0.0147     0.009  \n",
      "lr        0.2431  0.0102  0.0109     0.012  \n",
      "ada       0.2580  0.0103  0.0107     0.045  \n",
      "qda       0.2403  0.0095  0.0113     0.009  \n",
      "knn       0.2078 -0.0344 -0.0349     0.011  \n",
      "dt        0.1976 -0.0665 -0.0674     0.011  \n",
      "Best model (return_bucket): GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      "Multi-class – return_bucket results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.30256410256410254\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         down       0.14      0.10      0.12        48\n",
      "slightly_down       0.24      0.52      0.33        31\n",
      "  slightly_up       0.22      0.04      0.07        47\n",
      "           up       0.43      0.52      0.47        69\n",
      "\n",
      "     accuracy                           0.30       195\n",
      "    macro avg       0.26      0.30      0.25       195\n",
      " weighted avg       0.28      0.30      0.27       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup as clf_setup,\n",
    "    compare_models as clf_compare,\n",
    "    finalize_model as clf_finalize,\n",
    "    predict_model as clf_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION: return_bucket ================\\n\")\n",
    "\n",
    "cls_train_mc = train_df[feature_cols + [\"return_bucket\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_mc,\n",
    "    target=\"return_bucket\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# AutoML over all available classifiers\n",
    "best_mc = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (return_bucket):\", best_mc)\n",
    "\n",
    "final_mc = clf_finalize(best_mc)\n",
    "\n",
    "X_test_mc = test_df[feature_cols].copy()\n",
    "y_test_mc = test_df[\"return_bucket\"].copy()\n",
    "\n",
    "pred_mc = clf_predict(final_mc, data=X_test_mc)\n",
    "pred_col_mc = get_prediction_column(pred_mc, feature_cols)\n",
    "y_pred_mc = pred_mc[pred_col_mc]\n",
    "\n",
    "print(\"\\nMulti-class – return_bucket results:\")\n",
    "print(\"Prediction column:\", pred_col_mc)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_mc, y_pred_mc))\n",
    "print(classification_report(y_test_mc, y_pred_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = Sentiment VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION: return_bucket ================\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                           (452, 8)  \n",
      "5                                           (452, 8)  \n",
      "6                                           (316, 8)  \n",
      "7                                           (136, 8)  \n",
      "8                                                  7  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              1684  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lr                    Logistic Regression    0.3134  0.0000  0.3134  0.1717   \n",
      "knn                K Neighbors Classifier    0.3068  0.5430  0.3068  0.3091   \n",
      "lda          Linear Discriminant Analysis    0.3037  0.0000  0.3037  0.3028   \n",
      "et                 Extra Trees Classifier    0.2921  0.5179  0.2921  0.2853   \n",
      "ada                  Ada Boost Classifier    0.2911  0.0000  0.2911  0.2941   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2887  0.5164  0.2887  0.2867   \n",
      "ridge                    Ridge Classifier    0.2879  0.0000  0.2879  0.1943   \n",
      "rf               Random Forest Classifier    0.2827  0.5212  0.2827  0.2770   \n",
      "xgboost         Extreme Gradient Boosting    0.2825  0.5199  0.2825  0.2713   \n",
      "svm                   SVM - Linear Kernel    0.2821  0.0000  0.2821  0.1534   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "catboost              CatBoost Classifier    0.2731  0.5196  0.2731  0.2816   \n",
      "gbc          Gradient Boosting Classifier    0.2727  0.0000  0.2727  0.2723   \n",
      "nb                            Naive Bayes    0.2694  0.5588  0.2694  0.2839   \n",
      "qda       Quadratic Discriminant Analysis    0.2656  0.0000  0.2656  0.2561   \n",
      "dt               Decision Tree Classifier    0.2191  0.4769  0.2191  0.2103   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lr        0.2183  0.0602  0.0744     0.011  \n",
      "knn       0.2994  0.0783  0.0796     0.010  \n",
      "lda       0.2952  0.0642  0.0655     0.008  \n",
      "et        0.2808  0.0532  0.0553     0.049  \n",
      "ada       0.2862  0.0524  0.0538     0.041  \n",
      "lightgbm  0.2754  0.0470  0.0495     0.040  \n",
      "ridge     0.2104  0.0274  0.0340     0.008  \n",
      "rf        0.2725  0.0383  0.0400     0.070  \n",
      "xgboost   0.2692  0.0375  0.0381     0.072  \n",
      "svm       0.1565  0.0173  0.0392     0.010  \n",
      "dummy     0.1189  0.0000  0.0000     0.008  \n",
      "catboost  0.2667  0.0253  0.0265     2.322  \n",
      "gbc       0.2670  0.0264  0.0264     0.217  \n",
      "nb        0.2489  0.0314  0.0322     0.009  \n",
      "qda       0.2381  0.0236  0.0253     0.008  \n",
      "dt        0.2123 -0.0464 -0.0471     0.010  \n",
      "Best model (return_bucket): LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Multi-class – return_bucket results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.4\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         down       0.00      0.00      0.00        48\n",
      "slightly_down       0.00      0.00      0.00        31\n",
      "  slightly_up       0.35      0.62      0.45        47\n",
      "           up       0.43      0.71      0.54        69\n",
      "\n",
      "     accuracy                           0.40       195\n",
      "    macro avg       0.20      0.33      0.25       195\n",
      " weighted avg       0.24      0.40      0.30       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup as clf_setup,\n",
    "    compare_models as clf_compare,\n",
    "    finalize_model as clf_finalize,\n",
    "    predict_model as clf_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION: return_bucket ================\\n\")\n",
    "\n",
    "cls_train_mc = train_df[feature_cols + [\"return_bucket\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_mc,\n",
    "    target=\"return_bucket\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# AutoML over all available classifiers\n",
    "best_mc = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (return_bucket):\", best_mc)\n",
    "\n",
    "final_mc = clf_finalize(best_mc)\n",
    "\n",
    "X_test_mc = test_df[feature_cols].copy()\n",
    "y_test_mc = test_df[\"return_bucket\"].copy()\n",
    "\n",
    "pred_mc = clf_predict(final_mc, data=X_test_mc)\n",
    "pred_col_mc = get_prediction_column(pred_mc, feature_cols)\n",
    "y_pred_mc = pred_mc[pred_col_mc]\n",
    "\n",
    "print(\"\\nMulti-class – return_bucket results:\")\n",
    "print(\"Prediction column:\", pred_col_mc)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_mc, y_pred_mc))\n",
    "print(classification_report(y_test_mc, y_pred_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = GenAI Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_score\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION: return_bucket ================\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                           (452, 2)  \n",
      "5                                           (452, 2)  \n",
      "6                                           (316, 2)  \n",
      "7                                           (136, 2)  \n",
      "8                                                  1  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              ff71  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "ridge                    Ridge Classifier    0.3324  0.0000  0.3324  0.1942   \n",
      "lda          Linear Discriminant Analysis    0.3323  0.0000  0.3323  0.1939   \n",
      "lr                    Logistic Regression    0.3258  0.0000  0.3258  0.1803   \n",
      "nb                            Naive Bayes    0.2944  0.5778  0.2944  0.2358   \n",
      "qda       Quadratic Discriminant Analysis    0.2944  0.0000  0.2944  0.2358   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2817  0.5343  0.2817  0.2911   \n",
      "knn                K Neighbors Classifier    0.2789  0.5701  0.2789  0.2752   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "xgboost         Extreme Gradient Boosting    0.2600  0.5401  0.2600  0.2681   \n",
      "gbc          Gradient Boosting Classifier    0.2598  0.0000  0.2598  0.2608   \n",
      "rf               Random Forest Classifier    0.2597  0.5399  0.2597  0.2586   \n",
      "catboost              CatBoost Classifier    0.2595  0.5334  0.2595  0.2628   \n",
      "dt               Decision Tree Classifier    0.2470  0.4934  0.2470  0.2409   \n",
      "svm                   SVM - Linear Kernel    0.2440  0.0000  0.2440  0.0897   \n",
      "ada                  Ada Boost Classifier    0.2410  0.0000  0.2410  0.2455   \n",
      "et                 Extra Trees Classifier    0.2311  0.4968  0.2311  0.2320   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "ridge     0.2382  0.0848  0.1015     0.008  \n",
      "lda       0.2379  0.0846  0.1015     0.008  \n",
      "lr        0.2301  0.0755  0.0912     0.009  \n",
      "nb        0.2341  0.0423  0.0517     0.009  \n",
      "qda       0.2341  0.0423  0.0517     0.008  \n",
      "lightgbm  0.2723  0.0365  0.0376     0.032  \n",
      "knn       0.2707  0.0401  0.0406     0.009  \n",
      "dummy     0.1189  0.0000  0.0000     0.008  \n",
      "xgboost   0.2547  0.0114  0.0116     0.035  \n",
      "gbc       0.2486  0.0086  0.0088     0.115  \n",
      "rf        0.2516  0.0099  0.0098     0.061  \n",
      "catboost  0.2524  0.0084  0.0084     0.439  \n",
      "dt        0.2372 -0.0054 -0.0059     0.009  \n",
      "svm       0.1118  0.0100  0.0106     0.010  \n",
      "ada       0.2336 -0.0212 -0.0222     0.036  \n",
      "et        0.2247 -0.0260 -0.0266     0.046  \n",
      "Best model (return_bucket): RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "                max_iter=None, positive=False, random_state=42, solver='auto',\n",
      "                tol=0.0001)\n",
      "\n",
      "Multi-class – return_bucket results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.35384615384615387\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         down       0.00      0.00      0.00        48\n",
      "slightly_down       0.67      0.06      0.12        31\n",
      "  slightly_up       0.29      0.68      0.41        47\n",
      "           up       0.42      0.51      0.46        69\n",
      "\n",
      "     accuracy                           0.35       195\n",
      "    macro avg       0.35      0.31      0.25       195\n",
      " weighted avg       0.33      0.35      0.28       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup as clf_setup,\n",
    "    compare_models as clf_compare,\n",
    "    finalize_model as clf_finalize,\n",
    "    predict_model as clf_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION: return_bucket ================\\n\")\n",
    "\n",
    "cls_train_mc = train_df[feature_cols + [\"return_bucket\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_mc,\n",
    "    target=\"return_bucket\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# AutoML over all available classifiers\n",
    "best_mc = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (return_bucket):\", best_mc)\n",
    "\n",
    "final_mc = clf_finalize(best_mc)\n",
    "\n",
    "X_test_mc = test_df[feature_cols].copy()\n",
    "y_test_mc = test_df[\"return_bucket\"].copy()\n",
    "\n",
    "pred_mc = clf_predict(final_mc, data=X_test_mc)\n",
    "pred_col_mc = get_prediction_column(pred_mc, feature_cols)\n",
    "y_pred_mc = pred_mc[pred_col_mc]\n",
    "\n",
    "print(\"\\nMulti-class – return_bucket results:\")\n",
    "print(\"Prediction column:\", pred_col_mc)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_mc, y_pred_mc))\n",
    "print(classification_report(y_test_mc, y_pred_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = Sectoral sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ CLASSIFICATION: return_bucket ================\n",
      "\n",
      "                    Description  \\\n",
      "0                    Session id   \n",
      "1                        Target   \n",
      "2                   Target type   \n",
      "3                Target mapping   \n",
      "4           Original data shape   \n",
      "5        Transformed data shape   \n",
      "6   Transformed train set shape   \n",
      "7    Transformed test set shape   \n",
      "8              Numeric features   \n",
      "9                    Preprocess   \n",
      "10              Imputation type   \n",
      "11           Numeric imputation   \n",
      "12       Categorical imputation   \n",
      "13               Fold Generator   \n",
      "14                  Fold Number   \n",
      "15                     CPU Jobs   \n",
      "16                      Use GPU   \n",
      "17               Log Experiment   \n",
      "18              Experiment Name   \n",
      "19                          USI   \n",
      "\n",
      "                                               Value  \n",
      "0                                                 42  \n",
      "1                                      return_bucket  \n",
      "2                                         Multiclass  \n",
      "3   down: 0, slightly_down: 1, slightly_up: 2, up: 3  \n",
      "4                                          (452, 11)  \n",
      "5                                          (452, 11)  \n",
      "6                                          (316, 11)  \n",
      "7                                          (136, 11)  \n",
      "8                                                 10  \n",
      "9                                               True  \n",
      "10                                            simple  \n",
      "11                                              mean  \n",
      "12                                              mode  \n",
      "13                                   StratifiedKFold  \n",
      "14                                                10  \n",
      "15                                                 1  \n",
      "16                                             False  \n",
      "17                                             False  \n",
      "18                                  clf-default-name  \n",
      "19                                              bcec  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "rf               Random Forest Classifier    0.2973  0.5379  0.2973  0.3141   \n",
      "gbc          Gradient Boosting Classifier    0.2973  0.0000  0.2973  0.3007   \n",
      "qda       Quadratic Discriminant Analysis    0.2820  0.0000  0.2820  0.2951   \n",
      "nb                            Naive Bayes    0.2787  0.5588  0.2787  0.2932   \n",
      "catboost              CatBoost Classifier    0.2784  0.5051  0.2784  0.2842   \n",
      "dummy                    Dummy Classifier    0.2752  0.5000  0.2752  0.0759   \n",
      "lightgbm  Light Gradient Boosting Machine    0.2749  0.5135  0.2749  0.2619   \n",
      "xgboost         Extreme Gradient Boosting    0.2693  0.5150  0.2693  0.2588   \n",
      "lr                    Logistic Regression    0.2660  0.0000  0.2660  0.2397   \n",
      "dt               Decision Tree Classifier    0.2660  0.5086  0.2660  0.2596   \n",
      "ridge                    Ridge Classifier    0.2660  0.0000  0.2660  0.2390   \n",
      "lda          Linear Discriminant Analysis    0.2565  0.0000  0.2565  0.2454   \n",
      "et                 Extra Trees Classifier    0.2561  0.5152  0.2561  0.2553   \n",
      "svm                   SVM - Linear Kernel    0.2435  0.0000  0.2435  0.2457   \n",
      "ada                  Ada Boost Classifier    0.2404  0.0000  0.2404  0.2389   \n",
      "knn                K Neighbors Classifier    0.2400  0.5081  0.2400  0.2510   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "rf        0.2925  0.0565  0.0571     0.072  \n",
      "gbc       0.2897  0.0567  0.0575     0.209  \n",
      "qda       0.2790  0.0400  0.0405     0.010  \n",
      "nb        0.2710  0.0341  0.0355     0.010  \n",
      "catboost  0.2746  0.0344  0.0356     1.297  \n",
      "dummy     0.1189  0.0000  0.0000     0.009  \n",
      "lightgbm  0.2619  0.0317  0.0325     0.041  \n",
      "xgboost   0.2606  0.0202  0.0204     0.060  \n",
      "lr        0.2426  0.0094  0.0092     0.012  \n",
      "dt        0.2587  0.0166  0.0167     0.011  \n",
      "ridge     0.2425  0.0099  0.0092     0.010  \n",
      "lda       0.2404 -0.0013 -0.0022     0.009  \n",
      "et        0.2505 -0.0002 -0.0001     0.056  \n",
      "svm       0.1822 -0.0162 -0.0125     0.012  \n",
      "ada       0.2338 -0.0144 -0.0141     0.040  \n",
      "knn       0.2323 -0.0093 -0.0094     0.012  \n",
      "Best model (return_bucket): RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       monotonic_cst=None, n_estimators=100, n_jobs=1,\n",
      "                       oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "Multi-class – return_bucket results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.23076923076923078\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         down       0.26      0.15      0.19        48\n",
      "slightly_down       0.12      0.19      0.15        31\n",
      "  slightly_up       0.14      0.19      0.16        47\n",
      "           up       0.43      0.33      0.38        69\n",
      "\n",
      "     accuracy                           0.23       195\n",
      "    macro avg       0.24      0.22      0.22       195\n",
      " weighted avg       0.27      0.23      0.24       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import (\n",
    "    setup as clf_setup,\n",
    "    compare_models as clf_compare,\n",
    "    finalize_model as clf_finalize,\n",
    "    predict_model as clf_predict,\n",
    ")\n",
    "\n",
    "print(\"\\n================ CLASSIFICATION: return_bucket ================\\n\")\n",
    "\n",
    "cls_train_mc = train_df[feature_cols + [\"return_bucket\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_mc,\n",
    "    target=\"return_bucket\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# AutoML over all available classifiers\n",
    "best_mc = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (return_bucket):\", best_mc)\n",
    "\n",
    "final_mc = clf_finalize(best_mc)\n",
    "\n",
    "X_test_mc = test_df[feature_cols].copy()\n",
    "y_test_mc = test_df[\"return_bucket\"].copy()\n",
    "\n",
    "pred_mc = clf_predict(final_mc, data=X_test_mc)\n",
    "pred_col_mc = get_prediction_column(pred_mc, feature_cols)\n",
    "y_pred_mc = pred_mc[pred_col_mc]\n",
    "\n",
    "print(\"\\nMulti-class – return_bucket results:\")\n",
    "print(\"Prediction column:\", pred_col_mc)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_mc, y_pred_mc))\n",
    "print(classification_report(y_test_mc, y_pred_mc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification model_2 [Target = direction_binary]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = All sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "    \"sentiment_score\",\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BINARY CLASSIFICATION: direction_binary ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape         (452, 19)\n",
      "5        Transformed data shape         (452, 19)\n",
      "6   Transformed train set shape         (316, 19)\n",
      "7    Transformed test set shape         (136, 19)\n",
      "8              Numeric features                18\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              c24e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "lda          Linear Discriminant Analysis    0.5344  0.5591  0.5344  0.5290   \n",
      "dt               Decision Tree Classifier    0.5217  0.5153  0.5217  0.5222   \n",
      "svm                   SVM - Linear Kernel    0.5123  0.5227  0.5123  0.4772   \n",
      "gbc          Gradient Boosting Classifier    0.5034  0.4820  0.5034  0.4980   \n",
      "qda       Quadratic Discriminant Analysis    0.4992  0.5320  0.4992  0.5129   \n",
      "ada                  Ada Boost Classifier    0.4905  0.4721  0.4905  0.4895   \n",
      "ridge                    Ridge Classifier    0.4845  0.5004  0.4845  0.4691   \n",
      "xgboost         Extreme Gradient Boosting    0.4844  0.4585  0.4844  0.4775   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4843  0.4775  0.4843  0.4805   \n",
      "nb                            Naive Bayes    0.4778  0.5020  0.4778  0.5001   \n",
      "catboost              CatBoost Classifier    0.4777  0.4739  0.4777  0.4688   \n",
      "rf               Random Forest Classifier    0.4715  0.4435  0.4715  0.4643   \n",
      "lr                    Logistic Regression    0.4655  0.4770  0.4655  0.4498   \n",
      "et                 Extra Trees Classifier    0.4588  0.4768  0.4588  0.4539   \n",
      "knn                K Neighbors Classifier    0.4493  0.4424  0.4493  0.4455   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dummy     0.3802  0.0000  0.0000     0.009  \n",
      "lda       0.5256  0.0468  0.0488     0.009  \n",
      "dt        0.5165  0.0314  0.0342     0.011  \n",
      "svm       0.3944 -0.0175  0.0152     0.010  \n",
      "gbc       0.4904 -0.0163 -0.0138     0.091  \n",
      "qda       0.4910  0.0136  0.0158     0.010  \n",
      "ada       0.4845 -0.0294 -0.0290     0.046  \n",
      "ridge     0.4599 -0.0642 -0.0669     0.009  \n",
      "xgboost   0.4754 -0.0486 -0.0504     0.035  \n",
      "lightgbm  0.4787 -0.0450 -0.0456     0.021  \n",
      "nb        0.4310  0.0005 -0.0026     0.009  \n",
      "catboost  0.4630 -0.0693 -0.0696     1.286  \n",
      "rf        0.4613 -0.0780 -0.0786     0.075  \n",
      "lr        0.4323 -0.1082 -0.1095     0.011  \n",
      "et        0.4469 -0.1055 -0.1030     0.053  \n",
      "knn       0.4450 -0.1124 -0.1147     0.014  \n",
      "Best model (direction_binary): DummyClassifier(constant=None, random_state=42, strategy='prior')\n",
      "\n",
      "Binary Classification – direction_binary results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.5948717948717949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.00      0.00      0.00        79\n",
      "          up       0.59      1.00      0.75       116\n",
      "\n",
      "    accuracy                           0.59       195\n",
      "   macro avg       0.30      0.50      0.37       195\n",
      "weighted avg       0.35      0.59      0.44       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ BINARY CLASSIFICATION: direction_binary ================\\n\")\n",
    "\n",
    "cls_train_bin = train_df[feature_cols + [\"direction_binary\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_bin,\n",
    "    target=\"direction_binary\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_bin = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (direction_binary):\", best_bin)\n",
    "\n",
    "final_bin = clf_finalize(best_bin)\n",
    "\n",
    "X_test_bin = test_df[feature_cols].copy()\n",
    "y_test_bin = test_df[\"direction_binary\"].copy()\n",
    "\n",
    "pred_bin = clf_predict(final_bin, data=X_test_bin)\n",
    "pred_col_bin = get_prediction_column(pred_bin, feature_cols)\n",
    "y_pred_bin = pred_bin[pred_col_bin]\n",
    "\n",
    "print(\"\\nBinary Classification – direction_binary results:\")\n",
    "print(\"Prediction column:\", pred_col_bin)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_compound_mean\",\n",
    "    \"sentiment_compound_std\",\n",
    "    \"sentiment_compound_min\",\n",
    "    \"sentiment_compound_max\",\n",
    "    \"sentiment_pos_mean\",\n",
    "    \"sentiment_neg_mean\",\n",
    "    \"sentiment_neu_mean\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BINARY CLASSIFICATION: direction_binary ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape          (452, 8)\n",
      "5        Transformed data shape          (452, 8)\n",
      "6   Transformed train set shape          (316, 8)\n",
      "7    Transformed test set shape          (136, 8)\n",
      "8              Numeric features                 7\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              b00b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "lr                    Logistic Regression    0.5412  0.4809  0.5412  0.2930   \n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "ridge                    Ridge Classifier    0.5319  0.5023  0.5319  0.4823   \n",
      "lda          Linear Discriminant Analysis    0.5098  0.5308  0.5098  0.4978   \n",
      "qda       Quadratic Discriminant Analysis    0.5062  0.5291  0.5062  0.5436   \n",
      "svm                   SVM - Linear Kernel    0.5030  0.4994  0.5030  0.3314   \n",
      "ada                  Ada Boost Classifier    0.4808  0.4564  0.4808  0.4762   \n",
      "dt               Decision Tree Classifier    0.4781  0.4751  0.4781  0.4787   \n",
      "nb                            Naive Bayes    0.4779  0.5179  0.4779  0.5057   \n",
      "gbc          Gradient Boosting Classifier    0.4751  0.4539  0.4751  0.4699   \n",
      "rf               Random Forest Classifier    0.4622  0.4347  0.4622  0.4563   \n",
      "knn                K Neighbors Classifier    0.4531  0.4067  0.4531  0.4457   \n",
      "catboost              CatBoost Classifier    0.4497  0.4362  0.4497  0.4399   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4402  0.4299  0.4402  0.4380   \n",
      "xgboost         Extreme Gradient Boosting    0.4368  0.4415  0.4368  0.4336   \n",
      "et                 Extra Trees Classifier    0.4179  0.4278  0.4179  0.4111   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "lr        0.3802  0.0000  0.0000     0.010  \n",
      "dummy     0.3802  0.0000  0.0000     0.008  \n",
      "ridge     0.3998 -0.0114  0.0022     0.009  \n",
      "lda       0.4922 -0.0070 -0.0092     0.009  \n",
      "qda       0.4604  0.0534  0.0655     0.008  \n",
      "svm       0.3589 -0.0137 -0.0128     0.009  \n",
      "ada       0.4763 -0.0547 -0.0550     0.039  \n",
      "dt        0.4771 -0.0498 -0.0499     0.009  \n",
      "nb        0.4284  0.0031  0.0029     0.008  \n",
      "gbc       0.4688 -0.0646 -0.0661     0.066  \n",
      "rf        0.4563 -0.0914 -0.0931     0.065  \n",
      "knn       0.4424 -0.1037 -0.1097     0.009  \n",
      "catboost  0.4395 -0.1218 -0.1247     0.814  \n",
      "lightgbm  0.4371 -0.1314 -0.1315     0.017  \n",
      "xgboost   0.4324 -0.1349 -0.1377     0.029  \n",
      "et        0.4124 -0.1811 -0.1836     0.049  \n",
      "Best model (direction_binary): LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "Binary Classification – direction_binary results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.5948717948717949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.00      0.00      0.00        79\n",
      "          up       0.59      1.00      0.75       116\n",
      "\n",
      "    accuracy                           0.59       195\n",
      "   macro avg       0.30      0.50      0.37       195\n",
      "weighted avg       0.35      0.59      0.44       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ BINARY CLASSIFICATION: direction_binary ================\\n\")\n",
    "\n",
    "cls_train_bin = train_df[feature_cols + [\"direction_binary\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_bin,\n",
    "    target=\"direction_binary\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_bin = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (direction_binary):\", best_bin)\n",
    "\n",
    "final_bin = clf_finalize(best_bin)\n",
    "\n",
    "X_test_bin = test_df[feature_cols].copy()\n",
    "y_test_bin = test_df[\"direction_binary\"].copy()\n",
    "\n",
    "pred_bin = clf_predict(final_bin, data=X_test_bin)\n",
    "pred_col_bin = get_prediction_column(pred_bin, feature_cols)\n",
    "y_pred_bin = pred_bin[pred_col_bin]\n",
    "\n",
    "print(\"\\nBinary Classification – direction_binary results:\")\n",
    "print(\"Prediction column:\", pred_col_bin)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = GenAI sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_score\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BINARY CLASSIFICATION: direction_binary ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape          (452, 2)\n",
      "5        Transformed data shape          (452, 2)\n",
      "6   Transformed train set shape          (316, 2)\n",
      "7    Transformed test set shape          (136, 2)\n",
      "8              Numeric features                 1\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              6c8e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "gbc          Gradient Boosting Classifier    0.5636  0.5711  0.5636  0.5591   \n",
      "et                 Extra Trees Classifier    0.5538  0.5429  0.5538  0.5531   \n",
      "knn                K Neighbors Classifier    0.5508  0.5495  0.5508  0.5478   \n",
      "ridge                    Ridge Classifier    0.5413  0.5371  0.5413  0.3573   \n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "rf               Random Forest Classifier    0.5382  0.5677  0.5382  0.5334   \n",
      "lr                    Logistic Regression    0.5381  0.5371  0.5381  0.2922   \n",
      "dt               Decision Tree Classifier    0.5381  0.5482  0.5381  0.5369   \n",
      "lda          Linear Discriminant Analysis    0.5381  0.5371  0.5381  0.3565   \n",
      "xgboost         Extreme Gradient Boosting    0.5316  0.5453  0.5316  0.5305   \n",
      "svm                   SVM - Linear Kernel    0.5253  0.5114  0.5253  0.3044   \n",
      "ada                  Ada Boost Classifier    0.5220  0.5728  0.5220  0.5137   \n",
      "nb                            Naive Bayes    0.5125  0.5303  0.5125  0.4961   \n",
      "qda       Quadratic Discriminant Analysis    0.5125  0.5303  0.5125  0.4961   \n",
      "lightgbm  Light Gradient Boosting Machine    0.5123  0.5493  0.5123  0.5054   \n",
      "catboost              CatBoost Classifier    0.4935  0.5521  0.4935  0.4829   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "gbc       0.5537  0.1103  0.1111     0.035  \n",
      "et        0.5497  0.0968  0.0982     0.048  \n",
      "knn       0.5429  0.0882  0.0888     0.009  \n",
      "ridge     0.3934  0.0033  0.0142     0.009  \n",
      "dummy     0.3802  0.0000  0.0000     0.008  \n",
      "rf        0.5315  0.0606  0.0604     0.060  \n",
      "lr        0.3787 -0.0062 -0.0169     0.009  \n",
      "dt        0.5336  0.0660  0.0666     0.009  \n",
      "lda       0.3918 -0.0031 -0.0024     0.008  \n",
      "xgboost   0.5254  0.0526  0.0535     0.018  \n",
      "svm       0.3675 -0.0012 -0.0026     0.009  \n",
      "ada       0.5096  0.0255  0.0231     0.036  \n",
      "nb        0.4880  0.0026 -0.0041     0.013  \n",
      "qda       0.4880  0.0026 -0.0041     0.009  \n",
      "lightgbm  0.4983  0.0016  0.0024     0.015  \n",
      "catboost  0.4790 -0.0376 -0.0395     0.237  \n",
      "Best model (direction_binary): GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='log_loss', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                           n_estimators=100, n_iter_no_change=None,\n",
      "                           random_state=42, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "\n",
      "Binary Classification – direction_binary results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.5128205128205128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.39      0.37      0.38        79\n",
      "          up       0.59      0.61      0.60       116\n",
      "\n",
      "    accuracy                           0.51       195\n",
      "   macro avg       0.49      0.49      0.49       195\n",
      "weighted avg       0.51      0.51      0.51       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ BINARY CLASSIFICATION: direction_binary ================\\n\")\n",
    "\n",
    "cls_train_bin = train_df[feature_cols + [\"direction_binary\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_bin,\n",
    "    target=\"direction_binary\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_bin = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (direction_binary):\", best_bin)\n",
    "\n",
    "final_bin = clf_finalize(best_bin)\n",
    "\n",
    "X_test_bin = test_df[feature_cols].copy()\n",
    "y_test_bin = test_df[\"direction_binary\"].copy()\n",
    "\n",
    "pred_bin = clf_predict(final_bin, data=X_test_bin)\n",
    "pred_col_bin = get_prediction_column(pred_bin, feature_cols)\n",
    "y_pred_bin = pred_bin[pred_col_bin]\n",
    "\n",
    "print(\"\\nBinary Classification – direction_binary results:\")\n",
    "print(\"Prediction column:\", pred_col_bin)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features = Sectoral Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    \"sentiment_Airlines\",\n",
    "    \"sentiment_Automobile\",\n",
    "    \"sentiment_Corporate\",\n",
    "    \"sentiment_Economy\",\n",
    "    \"sentiment_Energy\",\n",
    "    \"sentiment_Geo-Political\", \n",
    "    \"sentiment_Healthcare\",\n",
    "    \"sentiment_Technology\",\n",
    "    \"sentiment_US Politics\",\n",
    "    \"overall_sentiment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ BINARY CLASSIFICATION: direction_binary ================\n",
      "\n",
      "                    Description             Value\n",
      "0                    Session id                42\n",
      "1                        Target  direction_binary\n",
      "2                   Target type            Binary\n",
      "3                Target mapping    down: 0, up: 1\n",
      "4           Original data shape         (452, 11)\n",
      "5        Transformed data shape         (452, 11)\n",
      "6   Transformed train set shape         (316, 11)\n",
      "7    Transformed test set shape         (136, 11)\n",
      "8              Numeric features                10\n",
      "9                    Preprocess              True\n",
      "10              Imputation type            simple\n",
      "11           Numeric imputation              mean\n",
      "12       Categorical imputation              mode\n",
      "13               Fold Generator   StratifiedKFold\n",
      "14                  Fold Number                10\n",
      "15                     CPU Jobs                 1\n",
      "16                      Use GPU             False\n",
      "17               Log Experiment             False\n",
      "18              Experiment Name  clf-default-name\n",
      "19                          USI              00b9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
      "dummy                    Dummy Classifier    0.5412  0.5000  0.5412  0.2930   \n",
      "xgboost         Extreme Gradient Boosting    0.5161  0.5059  0.5161  0.5148   \n",
      "rf               Random Forest Classifier    0.5157  0.4859  0.5157  0.5076   \n",
      "gbc          Gradient Boosting Classifier    0.5128  0.4870  0.5128  0.5146   \n",
      "ada                  Ada Boost Classifier    0.5041  0.4914  0.5041  0.5019   \n",
      "svm                   SVM - Linear Kernel    0.5004  0.4564  0.5004  0.4274   \n",
      "lightgbm  Light Gradient Boosting Machine    0.4939  0.4945  0.4939  0.4924   \n",
      "catboost              CatBoost Classifier    0.4907  0.5101  0.4907  0.4831   \n",
      "lr                    Logistic Regression    0.4878  0.4568  0.4878  0.4943   \n",
      "ridge                    Ridge Classifier    0.4847  0.4571  0.4847  0.4752   \n",
      "lda          Linear Discriminant Analysis    0.4847  0.4538  0.4847  0.4755   \n",
      "et                 Extra Trees Classifier    0.4782  0.4826  0.4782  0.4659   \n",
      "qda       Quadratic Discriminant Analysis    0.4779  0.4659  0.4779  0.4771   \n",
      "nb                            Naive Bayes    0.4749  0.4560  0.4749  0.4697   \n",
      "dt               Decision Tree Classifier    0.4743  0.4730  0.4743  0.4768   \n",
      "knn                K Neighbors Classifier    0.4587  0.4495  0.4587  0.4558   \n",
      "\n",
      "              F1   Kappa     MCC  TT (Sec)  \n",
      "dummy     0.3802  0.0000  0.0000     0.009  \n",
      "xgboost   0.5113  0.0208  0.0217     0.026  \n",
      "rf        0.5043  0.0130  0.0107     0.067  \n",
      "gbc       0.5067  0.0139  0.0178     0.061  \n",
      "ada       0.4967 -0.0083 -0.0059     0.044  \n",
      "svm       0.4261 -0.0079 -0.0153     0.010  \n",
      "lightgbm  0.4894 -0.0227 -0.0226     0.019  \n",
      "catboost  0.4769 -0.0411 -0.0412     0.512  \n",
      "lr        0.4510 -0.0617 -0.0474     0.011  \n",
      "ridge     0.4500 -0.0670 -0.0639     0.009  \n",
      "lda       0.4508 -0.0672 -0.0639     0.010  \n",
      "et        0.4639 -0.0703 -0.0729     0.052  \n",
      "qda       0.4745 -0.0530 -0.0533     0.010  \n",
      "nb        0.4568 -0.0803 -0.0752     0.009  \n",
      "dt        0.4736 -0.0533 -0.0538     0.010  \n",
      "knn       0.4551 -0.0931 -0.0946     0.010  \n",
      "Best model (direction_binary): DummyClassifier(constant=None, random_state=42, strategy='prior')\n",
      "\n",
      "Binary Classification – direction_binary results:\n",
      "Prediction column: prediction_label\n",
      "Accuracy: 0.5948717948717949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.00      0.00      0.00        79\n",
      "          up       0.59      1.00      0.75       116\n",
      "\n",
      "    accuracy                           0.59       195\n",
      "   macro avg       0.30      0.50      0.37       195\n",
      "weighted avg       0.35      0.59      0.44       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ BINARY CLASSIFICATION: direction_binary ================\\n\")\n",
    "\n",
    "cls_train_bin = train_df[feature_cols + [\"direction_binary\"]].copy()\n",
    "\n",
    "clf_setup(\n",
    "    data=cls_train_bin,\n",
    "    target=\"direction_binary\",\n",
    "    session_id=42,\n",
    "    html=False,\n",
    "    log_experiment=False,\n",
    "    n_jobs=1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_bin = clf_compare(sort=\"Accuracy\", turbo=True)\n",
    "print(\"Best model (direction_binary):\", best_bin)\n",
    "\n",
    "final_bin = clf_finalize(best_bin)\n",
    "\n",
    "X_test_bin = test_df[feature_cols].copy()\n",
    "y_test_bin = test_df[\"direction_binary\"].copy()\n",
    "\n",
    "pred_bin = clf_predict(final_bin, data=X_test_bin)\n",
    "pred_col_bin = get_prediction_column(pred_bin, feature_cols)\n",
    "y_pred_bin = pred_bin[pred_col_bin]\n",
    "\n",
    "print(\"\\nBinary Classification – direction_binary results:\")\n",
    "print(\"Prediction column:\", pred_col_bin)\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bin, y_pred_bin))\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
